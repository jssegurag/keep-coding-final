# 05. Implementaci√≥n del Sistema de Consultas - MVP RAG

## üéØ Objetivo
Implementar el sistema de consultas con integraci√≥n de Gemini 2.0 Flash Lite, extracci√≥n de filtros mejorada, b√∫squeda h√≠brida y trazabilidad de respuestas, manteniendo coherencia con la arquitectura y metadatos ya implementados.

## üìã Tareas a Ejecutar

### 1. Actualizar Configuraci√≥n
Actualizar `config/settings.py` para incluir configuraci√≥n de Gemini:
```python
# Configuraci√≥n de Gemini para consultas
GOOGLE_MODEL: Final[str] = "gemini-2.0-flash-lite"
QUERY_LOG_FILE: Final[str] = "logs/query.log"
QUERY_TIMEOUT: Final[int] = 30  # segundos
MAX_CONTEXT_LENGTH: Final[int] = 4000  # tokens
```

### 2. Crear M√≥dulo de Consultas
Crear `src/query/query_handler.py`:
```python
"""
M√≥dulo para manejo de consultas con Gemini y trazabilidad
"""
import google.generativeai as genai
import re
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from config.settings import GOOGLE_API_KEY, GOOGLE_MODEL, QUERY_LOG_FILE
from src.indexing.chroma_indexer import ChromaIndexer
from src.utils.text_utils import normalize_text, extract_legal_entities
from src.utils.logger import setup_logger

logger = setup_logger(__name__, QUERY_LOG_FILE)

class QueryHandler:
    def __init__(self):
        # Configurar Gemini
        genai.configure(api_key=GOOGLE_API_KEY)
        self.model = genai.GenerativeModel(GOOGLE_MODEL)
        
        # Inicializar indexador
        self.indexer = ChromaIndexer()
        
        # Configurar prompt estructurado
        self.prompt_template = self._create_prompt_template()
        
    def _create_prompt_template(self) -> str:
        """Crear template de prompt estructurado"""
        return """
Contexto: {context}

Pregunta del usuario: {query}

Instrucciones espec√≠ficas:
- Si la pregunta busca un resumen, genera un resumen estructurado del expediente
- Si la pregunta es espec√≠fica sobre contenido, responde bas√°ndote √∫nicamente en el contexto proporcionado
- Si la pregunta es sobre metadatos (fechas, nombres, cuant√≠as), extrae la informaci√≥n relevante
- Si la informaci√≥n no est√° en el contexto, responde: "No se encuentra en el expediente proporcionado."
- Responde en espa√±ol de manera profesional y jur√≠dica
- Al final de cada respuesta, incluye: "Fuente: {document_id}, Chunk {chunk_position} de {total_chunks}"

Tareas posibles:
- Resumir el contenido legal
- Responder preguntas espec√≠ficas del contenido
- Extraer campos clave como fechas, cuant√≠as o nombres
- Identificar tipos de medidas cautelares

Respuesta:
"""
    
    def _extract_filters_from_query(self, query: str) -> Dict[str, any]:
        """Extraer filtros de la consulta con normalizaci√≥n"""
        filters = {}
        
        # Normalizar consulta
        normalized_query = normalize_text(query)
        
        # Extraer entidades legales
        entities = extract_legal_entities(query)
        
        # Mapear entidades a filtros usando los campos normalizados existentes
        if entities['names']:
            # Usar el primer nombre encontrado como demandante
            filters['demandante_normalized'] = normalize_text(entities['names'][0])
        
        if entities['dates']:
            # Usar la primera fecha encontrada
            filters['fecha_normalized'] = entities['dates'][0]
        
        if entities['amounts']:
            # Usar la primera cantidad encontrada
            amount_clean = ''.join(filter(str.isdigit, entities['amounts'][0]))
            filters['cuantia_normalized'] = amount_clean
        
        # Detectar tipos de medida
        legal_terms = entities['legal_terms']
        if 'embargo' in legal_terms:
            filters['tipo_medida'] = 'Embargo'
        elif 'medida cautelar' in legal_terms:
            filters['tipo_medida'] = 'Medida Cautelar'
        
        # Patrones espec√≠ficos para consultas comunes
        patterns = {
            'demandante': r'(?:demandante|actor|solicitante)\s+(?:es\s+)?([A-Z√Å√â√ç√ì√ö√ë\s]+)',
            'demandado': r'(?:demandado|demandada|entidad)\s+(?:es\s+)?([A-Z√Å√â√ç√ì√ö√ë\s]+)',
            'cuantia': r'(?:cuant√≠a|monto|valor)\s+(?:es\s+)?(\$?[\d,\.]+)',
            'fecha': r'(?:fecha|d√≠a)\s+(?:es\s+)?(\d{1,2}[/-]\d{1,2}[/-]\d{4})'
        }
        
        for filter_key, pattern in patterns.items():
            matches = re.findall(pattern, query, re.IGNORECASE)
            if matches:
                if filter_key == 'demandante':
                    filters['demandante_normalized'] = normalize_text(matches[0])
                elif filter_key == 'demandado':
                    filters['demandado_normalized'] = normalize_text(matches[0])
                elif filter_key == 'cuantia':
                    amount_clean = ''.join(filter(str.isdigit, matches[0]))
                    filters['cuantia_normalized'] = amount_clean
                elif filter_key == 'fecha':
                    filters['fecha_normalized'] = matches[0]
        
        return filters
    
    def _format_context_for_prompt(self, search_results: Dict[str, any]) -> str:
        """Formatear contexto para el prompt"""
        if 'error' in search_results:
            return "No se encontraron documentos relevantes para la consulta."
        
        results = search_results['results']
        
        if not results['documents']:
            return "No se encontraron documentos relevantes para la consulta."
        
        context_parts = []
        
        # Procesar documentos y metadatos
        documents = results['documents'][0] if results['documents'] else []
        metadatas = results['metadatas'][0] if results['metadatas'] else []
        
        for i, (doc, metadata) in enumerate(zip(documents, metadatas)):
            # Extraer informaci√≥n de fuente usando metadatos reales
            document_id = metadata.get('document_id', 'unknown')
            chunk_position = metadata.get('chunk_position', 0)
            total_chunks = metadata.get('total_chunks', 0)
            
            # Formatear chunk
            chunk_text = doc[:500] + "..." if len(doc) > 500 else doc
            chunk_info = f"[Chunk {chunk_position}/{total_chunks} del documento {document_id}]"
            
            context_parts.append(f"{chunk_info}\n{chunk_text}")
        
        return "\n\n".join(context_parts)
    
    def _extract_source_info(self, search_results: Dict[str, any]) -> Dict[str, any]:
        """Extraer informaci√≥n de fuente de los resultados"""
        if 'error' in search_results or not search_results['results']['metadatas']:
            return {"document_id": "unknown", "chunk_position": 0, "total_chunks": 0}
        
        # Usar el primer resultado como fuente principal
        metadatas = search_results['results']['metadatas'][0]
        if metadatas:
            first_metadata = metadatas[0]
            
            return {
                "document_id": first_metadata.get('document_id', 'unknown'),
                "chunk_position": first_metadata.get('chunk_position', 0),
                "total_chunks": first_metadata.get('total_chunks', 0)
            }
        
        return {"document_id": "unknown", "chunk_position": 0, "total_chunks": 0}
    
    def _generate_response_with_gemini(self, context: str, query: str, source_info: Dict[str, any]) -> str:
        """Generar respuesta usando Gemini"""
        try:
            # Construir prompt completo
            prompt = self.prompt_template.format(
                context=context,
                query=query
            )
            
            # Generar respuesta
            response = self.model.generate_content(prompt)
            
            # A√±adir informaci√≥n de fuente
            source_text = f"\n\nFuente: {source_info['document_id']}, Chunk {source_info['chunk_position']} de {source_info['total_chunks']}"
            
            return response.text + source_text
            
        except Exception as e:
            logger.error(f"Error generando respuesta con Gemini: {e}")
            return f"Error generando respuesta: {str(e)}"
    
    def handle_query(self, query: str, n_results: int = 10) -> Dict[str, any]:
        """
        Manejar consulta completa
        
        Args:
            query: Consulta del usuario
            n_results: N√∫mero de resultados a buscar
            
        Returns:
            Respuesta estructurada
        """
        logger.info(f"Procesando consulta: {query}")
        
        try:
            # Extraer filtros de la consulta
            filters = self._extract_filters_from_query(query)
            logger.info(f"Filtros extra√≠dos: {filters}")
            
            # Realizar b√∫squeda h√≠brida
            search_results = self.indexer.search_similar(
                query=query,
                n_results=n_results,
                where=filters if filters else None
            )
            
            # Formatear contexto para el prompt
            context = self._format_context_for_prompt(search_results)
            
            # Extraer informaci√≥n de fuente
            source_info = self._extract_source_info(search_results)
            
            # Generar respuesta con Gemini
            response = self._generate_response_with_gemini(context, query, source_info)
            
            result = {
                "query": query,
                "response": response,
                "filters_used": filters,
                "search_results_count": search_results.get('total_found', 0),
                "source_info": source_info,
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"Consulta procesada exitosamente: {query}")
            return result
            
        except Exception as e:
            logger.error(f"Error procesando consulta '{query}': {e}")
            return {
                "query": query,
                "response": f"Error procesando la consulta: {str(e)}",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def handle_batch_queries(self, queries: List[str]) -> List[Dict[str, any]]:
        """Manejar m√∫ltiples consultas"""
        results = []
        
        for query in queries:
            result = self.handle_query(query)
            results.append(result)
        
        return results
```

### 3. Crear M√≥dulo de Extracci√≥n de Filtros Mejorado
Crear `src/query/filter_extractor.py`:
```python
"""
M√≥dulo mejorado para extracci√≥n de filtros de consultas
"""
import re
from typing import Dict, List, Optional
from src.utils.text_utils import normalize_text, extract_legal_entities

class FilterExtractor:
    def __init__(self):
        # Patrones espec√≠ficos para consultas legales
        self.patterns = {
            'demandante': [
                r'(?:demandante|actor|solicitante)\s+(?:es\s+)?([A-Z√Å√â√ç√ì√ö√ë\s]+)',
                r'(?:el\s+)?demandante\s+([A-Z√Å√â√ç√ì√ö√ë\s]+)',
                r'([A-Z√Å√â√ç√ì√ö√ë\s]+)\s+(?:es\s+el\s+)?demandante'
            ],
            'demandado': [
                r'(?:demandado|demandada|entidad)\s+(?:es\s+)?([A-Z√Å√â√ç√ì√ö√ë\s]+)',
                r'(?:el\s+)?demandado\s+([A-Z√Å√â√ç√ì√ö√ë\s]+)',
                r'([A-Z√Å√â√ç√ì√ö√ë\s]+)\s+(?:es\s+el\s+)?demandado'
            ],
            'cuantia': [
                r'(?:cuant√≠a|monto|valor)\s+(?:es\s+)?(\$?[\d,\.]+)',
                r'(\$?[\d,\.]+)\s+(?:es\s+la\s+)?cuant√≠a',
                r'por\s+(\$?[\d,\.]+)'
            ],
            'fecha': [
                r'(?:fecha|d√≠a)\s+(?:es\s+)?(\d{1,2}[/-]\d{1,2}[/-]\d{4})',
                r'(\d{1,2}[/-]\d{1,2}[/-]\d{4})\s+(?:es\s+la\s+)?fecha',
                r'el\s+(\d{1,2}\s+de\s+[a-z]+\s+de\s+\d{4})'
            ],
            'tipo_medida': [
                r'(?:tipo\s+de\s+)?medida\s+(?:es\s+)?([a-z√°√©√≠√≥√∫√±\s]+)',
                r'([a-z√°√©√≠√≥√∫√±\s]+)\s+(?:es\s+el\s+)?tipo\s+de\s+medida',
                r'(embargo|medida\s+cautelar|secuestro|prohibici√≥n)'
            ]
        }
        
        # T√©rminos de medida mapeados
        self.measure_mapping = {
            'embargo': 'Embargo',
            'medida cautelar': 'Medida Cautelar',
            'secuestro': 'Secuestro',
            'prohibici√≥n': 'Prohibici√≥n',
            'suspensi√≥n': 'Suspensi√≥n'
        }
    
    def extract_filters(self, query: str) -> Dict[str, any]:
        """Extraer filtros de la consulta"""
        filters = {}
        
        # Normalizar consulta
        normalized_query = normalize_text(query)
        
        # Extraer entidades legales
        entities = extract_legal_entities(query)
        
        # Procesar cada tipo de filtro
        for filter_type, patterns in self.patterns.items():
            value = self._extract_with_patterns(query, patterns)
            
            if value:
                if filter_type == 'demandante':
                    filters['demandante_normalized'] = normalize_text(value)
                elif filter_type == 'demandado':
                    filters['demandado_normalized'] = normalize_text(value)
                elif filter_type == 'cuantia':
                    amount_clean = ''.join(filter(str.isdigit, value))
                    filters['cuantia_normalized'] = amount_clean
                elif filter_type == 'fecha':
                    filters['fecha_normalized'] = value
                elif filter_type == 'tipo_medida':
                    normalized_measure = normalize_text(value)
                    for key, mapped_value in self.measure_mapping.items():
                        if key in normalized_measure:
                            filters['tipo_medida'] = mapped_value
                            break
        
        # Usar entidades extra√≠das como respaldo
        if not filters.get('demandante_normalized') and entities['names']:
            filters['demandante_normalized'] = normalize_text(entities['names'][0])
        
        if not filters.get('cuantia_normalized') and entities['amounts']:
            amount_clean = ''.join(filter(str.isdigit, entities['amounts'][0]))
            filters['cuantia_normalized'] = amount_clean
        
        if not filters.get('fecha_normalized') and entities['dates']:
            filters['fecha_normalized'] = entities['dates'][0]
        
        return filters
    
    def _extract_with_patterns(self, text: str, patterns: List[str]) -> Optional[str]:
        """Extraer valor usando m√∫ltiples patrones"""
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                return matches[0].strip()
        return None
    
    def validate_filters(self, filters: Dict[str, any]) -> Dict[str, any]:
        """Validar y limpiar filtros"""
        validated = {}
        
        for key, value in filters.items():
            if value and str(value).strip():
                # Limpiar espacios extra
                cleaned_value = str(value).strip()
                
                # Validaciones espec√≠ficas
                if 'normalized' in key:
                    # Asegurar que est√© normalizado
                    cleaned_value = normalize_text(cleaned_value)
                
                validated[key] = cleaned_value
        
        return validated
```

### 4. Crear Script de Consultas Interactivo
Crear `scripts/interactive_query.py`:
```python
#!/usr/bin/env python3
"""
Script interactivo para probar consultas
"""
import sys
import os
import json
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.query.query_handler import QueryHandler
from src.query.filter_extractor import FilterExtractor

def main():
    print("ü§ñ Sistema de Consultas RAG - Modo Interactivo")
    print("=" * 50)
    print("Escribe 'salir' para terminar")
    print("Escribe 'ayuda' para ver ejemplos de consultas")
    print()
    
    # Inicializar componentes
    query_handler = QueryHandler()
    filter_extractor = FilterExtractor()
    
    # Ejemplos de consultas
    examples = [
        "¬øCu√°l es el demandante del expediente?",
        "¬øQu√© tipo de medida se solicit√≥?",
        "¬øCu√°l es la cuant√≠a del embargo?",
        "Resume el expediente RCCI2150725310",
        "¬øCu√°les son los hechos principales?",
        "embargos de Nury Romero"
    ]
    
    while True:
        try:
            # Obtener consulta del usuario
            query = input("\nüîç Tu consulta: ").strip()
            
            if query.lower() == 'salir':
                print("üëã ¬°Hasta luego!")
                break
            
            if query.lower() == 'ayuda':
                print("\nüìù Ejemplos de consultas:")
                for i, example in enumerate(examples, 1):
                    print(f"   {i}. {example}")
                continue
            
            if not query:
                print("‚ùå Por favor, ingresa una consulta v√°lida")
                continue
            
            print(f"\nüîÑ Procesando: {query}")
            
            # Extraer filtros (para debug)
            filters = filter_extractor.extract_filters(query)
            validated_filters = filter_extractor.validate_filters(filters)
            
            if validated_filters:
                print(f"üîç Filtros detectados: {validated_filters}")
            
            # Procesar consulta
            result = query_handler.handle_query(query)
            
            # Mostrar respuesta
            print(f"\nüí¨ Respuesta:")
            print("-" * 40)
            print(result['response'])
            print("-" * 40)
            
            # Mostrar informaci√≥n adicional
            print(f"\nüìä Informaci√≥n:")
            print(f"   - Resultados encontrados: {result['search_results_count']}")
            print(f"   - Fuente: {result['source_info']['document_id']}")
            print(f"   - Chunk: {result['source_info']['chunk_position']}/{result['source_info']['total_chunks']}")
            
        except KeyboardInterrupt:
            print("\n\nüëã ¬°Hasta luego!")
            break
        except Exception as e:
            print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    main()
```

### 5. Crear Tests Unitarios
Crear `tests/unit/test_query_system.py`:
```python
"""
Tests unitarios para el sistema de consultas
"""
import pytest
from unittest.mock import Mock, patch
from src.query.query_handler import QueryHandler
from src.query.filter_extractor import FilterExtractor

class TestQueryHandler:
    
    def setup_method(self):
        """Configurar antes de cada test"""
        with patch('google.generativeai.configure'):
            with patch('google.generativeai.GenerativeModel'):
                self.query_handler = QueryHandler()
    
    def test_extract_filters_from_query(self):
        """Test de extracci√≥n de filtros"""
        query = "¬øCu√°l es el demandante Juan P√©rez?"
        filters = self.query_handler._extract_filters_from_query(query)
        
        assert 'demandante_normalized' in filters
        assert filters['demandante_normalized'] == 'juan perez'
    
    def test_extract_filters_with_amount(self):
        """Test de extracci√≥n de filtros con cuant√≠a"""
        query = "¬øCu√°l es la cuant√≠a de $1,000,000?"
        filters = self.query_handler._extract_filters_from_query(query)
        
        assert 'cuantia_normalized' in filters
        assert filters['cuantia_normalized'] == '1000000'
    
    def test_extract_filters_with_date(self):
        """Test de extracci√≥n de filtros con fecha"""
        query = "¬øCu√°l es la fecha del 15/01/2024?"
        filters = self.query_handler._extract_filters_from_query(query)
        
        assert 'fecha_normalized' in filters
        assert filters['fecha_normalized'] == '15/01/2024'
    
    def test_format_context_for_prompt(self):
        """Test de formateo de contexto"""
        search_results = {
            'results': {
                'documents': [['Texto de prueba del chunk 1']],
                'metadatas': [[{
                    'document_id': 'test_doc',
                    'chunk_position': 1,
                    'total_chunks': 3
                }]]
            }
        }
        
        context = self.query_handler._format_context_for_prompt(search_results)
        
        assert 'test_doc' in context
        assert 'Chunk 1/3' in context
        assert 'Texto de prueba' in context
    
    def test_extract_source_info(self):
        """Test de extracci√≥n de informaci√≥n de fuente"""
        search_results = {
            'results': {
                'metadatas': [[{
                    'document_id': 'test_doc',
                    'chunk_position': 2,
                    'total_chunks': 5
                }]]
            }
        }
        
        source_info = self.query_handler._extract_source_info(search_results)
        
        assert source_info['document_id'] == 'test_doc'
        assert source_info['chunk_position'] == 2
        assert source_info['total_chunks'] == 5

class TestFilterExtractor:
    
    def setup_method(self):
        """Configurar antes de cada test"""
        self.extractor = FilterExtractor()
    
    def test_extract_demandante(self):
        """Test de extracci√≥n de demandante"""
        query = "El demandante es Juan P√©rez"
        filters = self.extractor.extract_filters(query)
        
        assert 'demandante_normalized' in filters
        assert filters['demandante_normalized'] == 'juan perez'
    
    def test_extract_cuantia(self):
        """Test de extracci√≥n de cuant√≠a"""
        query = "La cuant√≠a es $500,000"
        filters = self.extractor.extract_filters(query)
        
        assert 'cuantia_normalized' in filters
        assert filters['cuantia_normalized'] == '500000'
    
    def test_extract_tipo_medida(self):
        """Test de extracci√≥n de tipo de medida"""
        query = "El tipo de medida es embargo"
        filters = self.extractor.extract_filters(query)
        
        assert 'tipo_medida' in filters
        assert filters['tipo_medida'] == 'Embargo'
    
    def test_validate_filters(self):
        """Test de validaci√≥n de filtros"""
        filters = {
            'demandante_normalized': '  JUAN P√âREZ  ',
            'cuantia_normalized': '1000000',
            'empty_filter': ''
        }
        
        validated = self.extractor.validate_filters(filters)
        
        assert 'demandante_normalized' in validated
        assert validated['demandante_normalized'] == 'juan perez'
        assert 'cuantia_normalized' in validated
        assert 'empty_filter' not in validated
```

### 6. Crear Script de Evaluaci√≥n
Crear `scripts/evaluate_queries.py`:
```python
#!/usr/bin/env python3
"""
Script para evaluar consultas con preguntas de prueba
"""
import sys
import os
import json
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.query.query_handler import QueryHandler

def main():
    print("üìä Evaluaci√≥n del Sistema de Consultas")
    print("=" * 50)
    
    # Consultas de prueba
    test_queries = [
        "¬øCu√°l es el demandante del expediente?",
        "¬øQu√© tipo de medida se solicit√≥?",
        "¬øCu√°l es la cuant√≠a del embargo?",
        "¬øEn qu√© fecha se dict√≥ la medida?",
        "¬øCu√°les son los hechos principales del caso?",
        "¬øQu√© fundamentos jur√≠dicos se esgrimen?",
        "¬øCu√°les son las medidas cautelares solicitadas?",
        "Resume el expediente",
        "¬øCu√°l es el estado actual del proceso?",
        "¬øQui√©n es el juez del caso?"
    ]
    
    # Inicializar query handler
    query_handler = QueryHandler()
    
    results = []
    
    print(f"üß™ Evaluando {len(test_queries)} consultas...")
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n[{i}/{len(test_queries)}] Procesando: {query}")
        
        try:
            result = query_handler.handle_query(query)
            
            # Evaluar calidad de respuesta
            quality_score = evaluate_response_quality(result['response'])
            
            result['quality_score'] = quality_score
            results.append(result)
            
            print(f"   ‚úÖ Completado - Calidad: {quality_score}/5")
            
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
            results.append({
                'query': query,
                'error': str(e),
                'quality_score': 0
            })
    
    # Calcular estad√≠sticas
    successful = len([r for r in results if 'error' not in r])
    avg_quality = sum(r['quality_score'] for r in results) / len(results)
    
    print(f"\nüìä Resultados de Evaluaci√≥n:")
    print(f"   - Consultas exitosas: {successful}/{len(test_queries)}")
    print(f"   - Calidad promedio: {avg_quality:.2f}/5")
    print(f"   - Tasa de √©xito: {(successful/len(test_queries))*100:.1f}%")
    
    # Guardar resultados
    with open("logs/query_evaluation_results.json", "w") as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\nüíæ Resultados guardados en logs/query_evaluation_results.json")

def evaluate_response_quality(response: str) -> int:
    """Evaluar calidad de respuesta (1-5)"""
    if not response or "Error" in response:
        return 1
    
    # Criterios de calidad
    score = 0
    
    # Respuesta no vac√≠a
    if len(response) > 10:
        score += 1
    
    # Incluye informaci√≥n espec√≠fica
    if any(keyword in response.lower() for keyword in ['demandante', 'demandado', 'embargo', 'medida']):
        score += 1
    
    # Incluye fuente
    if 'Fuente:' in response:
        score += 1
    
    # Respuesta coherente
    if not response.startswith("No se encuentra"):
        score += 1
    
    # Respuesta completa
    if len(response) > 50:
        score += 1
    
    return score

if __name__ == "__main__":
    main()
```

## ‚úÖ Criterios de √âxito
- [ ] M√≥dulo `QueryHandler` implementado correctamente
- [ ] Extracci√≥n de filtros mejorada funcionando
- [ ] Integraci√≥n con Gemini funcionando
- [ ] Trazabilidad en respuestas implementada
- [ ] B√∫squeda h√≠brida operativa
- [ ] Tests unitarios pasando
- [ ] Script interactivo funcionando

## üîç Verificaci√≥n
Ejecutar los siguientes comandos:
```bash
# Probar consultas interactivas
python scripts/interactive_query.py

# Evaluar consultas
python scripts/evaluate_queries.py

# Ejecutar tests
python -m pytest tests/unit/test_query_system.py -v

# Verificar logs
cat logs/query.log
```

## üìä M√©tricas de Calidad
- **Tasa de √©xito de consultas**: > 80%
- **Calidad promedio de respuestas**: > 3.5/5
- **Trazabilidad**: 100% de respuestas con fuente
- **Tiempo de respuesta**: < 5 segundos por consulta

## üìù Notas Importantes
- La extracci√≥n de filtros debe ser robusta y tolerante a variaciones
- Las respuestas deben incluir siempre informaci√≥n de fuente
- El prompt estructurado es cr√≠tico para respuestas consistentes
- La evaluaci√≥n debe ejecutarse regularmente para monitorear calidad
- **Coherencia con metadatos existentes**: Usar campos normalizados ya implementados
- **Integraci√≥n con ChromaIndexer**: Aprovechar la funcionalidad de b√∫squeda existente 

---

## üõ†Ô∏è Ajustes y Mejoras Realizadas en la Implementaci√≥n Real (Desarrollo)

### Cambios Clave respecto al plan original:
- **B√∫squeda siempre sem√°ntica:** Se elimin√≥ el uso de filtros literales por defecto. El sistema busca en todos los chunks indexados usando embeddings, sin requerir coincidencia exacta de nombres, empresas o t√©rminos generales.
- **Correlaci√≥n inteligente con metadatos:** Las entidades extra√≠das de la consulta (nombres, fechas, cuant√≠as, expedientes, etc.) se correlacionan con los metadatos de los resultados encontrados, enriqueciendo la respuesta y resaltando coincidencias, pero sin filtrar resultados salvo casos estructurados.
- **Uso de filtros solo para consultas estructuradas:** Los filtros literales solo se aplican para campos como n√∫mero de expediente, fecha, cuant√≠a o tipo de medida, nunca para nombres o t√©rminos generales.
- **Respuestas enriquecidas y trazables:** Todas las respuestas incluyen fuente (documento, chunk) y resumen de metadatos relevantes, facilitando la trazabilidad y transparencia.
- **Refactorizaci√≥n SOLID/GRASP:** Se modulariz√≥ la l√≥gica de extracci√≥n de entidades, correlaci√≥n y generaci√≥n de respuestas, manteniendo bajo acoplamiento y alta cohesi√≥n.
- **Pruebas unitarias orientadas a casos reales:** Los tests cubren consultas generales y estructuradas, usando ejemplos y metadatos reales para validar la efectividad del sistema.

### Ejemplo de comportamiento tras los cambios:
- **Consulta general:**
  - Usuario: "tienes informaci√≥n de Coordinadora comercial de cargas CCC SA"
  - El sistema busca sem√°nticamente en todos los documentos y chunks, encuentra coincidencias en los metadatos y enriquece la respuesta mostrando la entidad correlacionada, sin requerir coincidencia literal.

- **Consulta estructurada:**
  - Usuario: "expediente numero RCCI2150725299"
  - El sistema extrae el n√∫mero de expediente y lo usa como filtro literal, recuperando el expediente exacto y mostrando la informaci√≥n relevante.

- **Consulta por cuant√≠a o fecha:**
  - Usuario: "¬øCu√°l es la cuant√≠a del embargo?"
  - El sistema extrae la entidad cuant√≠a, busca sem√°nticamente y resalta la cuant√≠a encontrada en los metadatos de los resultados.

### Validaci√≥n y pruebas:
- Se actualizaron y ampliaron los tests unitarios en `tests/unit/test_query_system.py` para cubrir estos escenarios.
- Se valid√≥ el sistema con documentos y expedientes reales, asegurando robustez y calidad en las respuestas.

> **Estos ajustes garantizan que el sistema de consultas act√∫e como un verdadero chat jur√≠dico inteligente, flexible y alineado a las mejores pr√°cticas de ingenier√≠a y procesamiento legal automatizado.** 