# Gu√≠a de Desarrollo - Sistema de Indexaci√≥n para Documentos Legales

## Configuraci√≥n Inicial

### Prerrequisitos
- Python 3.8 o superior
- Dependencias del paso 1, 2 y 3 instaladas
- Datos de entrada disponibles (CSV actualizado y archivos JSON de OCR)
- Sistema de embeddings validado del paso 2
- Sistema de chunking implementado del paso 3

### Pasos de Configuraci√≥n
1. Verificar que los pasos 1, 2 y 3 est√©n completados
2. Ejecutar: `python scripts/update_csv_for_pipeline.py`
3. Ejecutar: `python -m src.main` para procesar pipeline completo
4. Verificar indexaci√≥n: `python scripts/verify_indexing.py`
5. Ejecutar: `python -m pytest tests/unit/test_indexing.py -v`

## Estructura del Proyecto

### Organizaci√≥n por Capas (Arquitectura Limpia)
```
src/
‚îú‚îÄ‚îÄ indexing/
‚îÇ   ‚îî‚îÄ‚îÄ chroma_indexer.py        # Sistema principal de indexaci√≥n
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_steps/
‚îÇ       ‚îî‚îÄ‚îÄ indexing_step.py     # Paso de indexaci√≥n del pipeline
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ logger.py                 # Configuraci√≥n de logging
‚îî‚îÄ‚îÄ resources/                    # Recursos est√°ticos

scripts/
‚îú‚îÄ‚îÄ update_csv_for_pipeline.py    # Script para actualizar CSV
‚îî‚îÄ‚îÄ verify_indexing.py           # Script de verificaci√≥n de indexaci√≥n

tests/
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îî‚îÄ‚îÄ test_indexing.py         # Tests unitarios del indexador
‚îî‚îÄ‚îÄ integration/                  # Tests de integraci√≥n

logs/
‚îî‚îÄ‚îÄ indexing_results.json         # Resultados de indexaci√≥n

config/
‚îî‚îÄ‚îÄ settings.py                   # Configuraci√≥n centralizada

data/
‚îî‚îÄ‚îÄ chroma_db/                   # Base de datos vectorial
```

### Principios de Dise√±o Aplicados

#### SOLID Principles
- **SRP**: `ChromaIndexer` tiene responsabilidad √∫nica de indexaci√≥n
- **OCP**: Abierto para extensi√≥n (nuevos tipos de indexaci√≥n)
- **LSP**: Interfaces sustituibles (`IPipelineStep`)
- **ISP**: Interfaces espec√≠ficas por dominio
- **DIP**: Dependencia de abstracciones

#### GRASP Patterns
- **High Cohesion**: M√≥dulos con responsabilidades relacionadas
- **Low Coupling**: M√≠nima dependencia entre m√≥dulos
- **Protected Variations**: Interfaces estables
- **Information Expert**: Responsabilidades asignadas a expertos

## Comandos √ötiles

### Desarrollo
```bash
# Actualizar CSV para pipeline
python scripts/update_csv_for_pipeline.py

# Ejecutar pipeline completo con indexaci√≥n
python -m src.main

# Verificar indexaci√≥n
python scripts/verify_indexing.py

# Ejecutar tests unitarios
python -m pytest tests/unit/test_indexing.py -v

# Tests con cobertura
python -m pytest --cov=src/indexing

# Verificar resultados
cat logs/indexing_results.json
```

### Logging
- **Nivel**: INFO por defecto
- **Formato**: Sin emojis, texto estructurado
- **Archivo**: `logs/indexing.log`

### Testing
- **Unitarios**: Componentes individuales del indexador
- **Validaci√≥n**: Embeddings y metadatos
- **M√©tricas**: Tasa de √©xito, calidad de indexaci√≥n

## Configuraci√≥n

### Variables de Entorno (.env)
```bash
GOOGLE_API_KEY=tu_api_key_aqui
```

### Configuraci√≥n Centralizada (config/settings.py)
- `CHROMA_PERSIST_DIRECTORY`: Directorio de ChromaDB
- `CHROMA_COLLECTION_NAME`: Nombre de colecci√≥n
- `EMBEDDING_MODEL`: Modelo de embeddings
- `EMBEDDING_DIMENSIONS`: Dimensiones de embeddings (768)
- `CSV_METADATA_PATH`: Ruta del CSV actualizado
- `JSON_DOCS_PATH`: Ruta de documentos JSON

## Est√°ndares de C√≥digo

### Python
- PEP 8 para estilo
- Type hints obligatorios
- Docstrings descriptivos
- Manejo espec√≠fico de excepciones

### Logging
- Sin emojis en logs
- Niveles apropiados (DEBUG, INFO, WARNING, ERROR, CRITICAL)
- Contexto relevante en mensajes

### Testing
- Tests unitarios para cada componente
- Validaci√≥n de indexaci√≥n
- Evaluaci√≥n de calidad de embeddings
- Mocks para dependencias externas

## Arquitectura del Sistema

### Flujo Principal
1. **Carga de Metadatos**: Cargar CSV actualizado con rutas correctas
2. **Procesamiento de Documentos**: Cargar archivos JSON de OCR
3. **Extracci√≥n de Texto**: Concatenar textos de arrays `texts`
4. **Chunking**: Dividir texto en chunks optimizados
5. **Generaci√≥n de Embeddings**: Crear embeddings con SentenceTransformer
6. **Indexaci√≥n en ChromaDB**: Almacenar con metadatos normalizados
7. **Validaci√≥n**: Verificar calidad de indexaci√≥n

### Componentes Clave
- **ChromaIndexer**: Indexador principal con ChromaDB
- **IndexingStep**: Paso del pipeline de indexaci√≥n
- **MetadataNormalizer**: Normalizaci√≥n de metadatos
- **EmbeddingGenerator**: Generaci√≥n de embeddings
- **ChunkProcessor**: Procesamiento de chunks para indexaci√≥n

## Monitoreo y Debugging

### Logs
- Configuraci√≥n autom√°tica en `src/utils/logger.py`
- Rotaci√≥n de archivos de log
- Niveles configurables

### M√©tricas
- Tasa de √©xito de indexaci√≥n
- Calidad de embeddings
- Tiempo de procesamiento
- Uso de recursos

## Contribuci√≥n

### Flujo de Trabajo
1. Crear rama feature
2. Implementar siguiendo principios SOLID
3. A√±adir tests unitarios
4. Ejecutar validaciones
5. Crear pull request

### Criterios de Aceptaci√≥n
- Tests pasando
- Cobertura > 80%
- Sin code smells
- Documentaci√≥n actualizada
- Logs sin emojis

## Funcionalidades Implementadas

### Sistema de Indexaci√≥n
- **Indexaci√≥n por Documento**: Procesamiento individual con metadatos
- **Indexaci√≥n por Batch**: Procesamiento en lotes para eficiencia
- **Carga desde CSV**: Integraci√≥n con metadatos existentes
- **Normalizaci√≥n de Metadatos**: Limpieza y estandarizaci√≥n
- **Verificaci√≥n de Duplicados**: Prevenci√≥n de re-indexaci√≥n

### Integraci√≥n con Pipeline
- **IndexingStep**: Paso integrado en pipeline principal
- **Configuraci√≥n Autom√°tica**: Habilitaci√≥n/deshabilitaci√≥n por configuraci√≥n
- **Cache Inteligente**: Evita reprocesamiento innecesario
- **Manejo de Errores**: Recuperaci√≥n robusta de fallos

### Metadatos Jur√≠dicos
- **Informaci√≥n del Demandante**: Nombres, identificaci√≥n, ubicaci√≥n
- **Resoluciones**: N√∫meros de referencia y radicados
- **Tipo de Entidad**: Clasificaci√≥n de entidades jur√≠dicas
- **Metadatos de Archivo**: Informaci√≥n t√©cnica del documento

## M√©tricas de Calidad

### Efectividad de la Indexaci√≥n
- **Tasa de √âxito**: 100% de documentos procesados exitosamente
- **Cobertura**: 125/130 documentos (96.2% cobertura)
- **Calidad de Embeddings**: Compatible con modelo multiling√ºe
- **Metadatos Completos**: Informaci√≥n jur√≠dica preservada

### Rendimiento del Sistema
- **Procesamiento Paralelo**: Hasta 30 workers simult√°neos
- **Cache Efectivo**: 125 documentos ya procesados
- **Tiempo de Respuesta**: Optimizado para documentos grandes
- **Uso de Memoria**: Eficiente para datasets grandes

## Integraci√≥n con Otros Pasos

### Con Paso 2 (Validaci√≥n de Embeddings)
- Modelo `paraphrase-multilingual-mpnet-base-v2` validado
- Dimensiones de embeddings (768) compatibles
- Calidad de embeddings verificada

### Con Paso 3 (Chunking)
- Chunks optimizados para indexaci√≥n
- Metadatos preservados en chunks
- Overlap configurado para contexto

### Con Pipeline Principal
- Integraci√≥n autom√°tica en `main.py`
- Configuraci√≥n centralizada en `PipelineConfig`
- Orquestaci√≥n por `DocumentPipelineOrchestrator`

## Troubleshooting

### Problemas Comunes
1. **Error de columnas CSV**: Verificar estructura del CSV actualizado
2. **Archivos JSON no encontrados**: Verificar rutas en configuraci√≥n
3. **Embeddings duplicados**: Verificar IDs √∫nicos en ChromaDB
4. **Metadatos incompletos**: Revisar normalizaci√≥n de datos

### Soluciones
- **Script de Actualizaci√≥n**: `update_csv_for_pipeline.py` para corregir rutas
- **Validaci√≥n de Rutas**: Verificaci√≥n autom√°tica de archivos
- **Normalizaci√≥n Robusta**: Manejo de valores None y datos incompletos
- **Logging Detallado**: Seguimiento completo del proceso

## Estado del Desarrollo

### Completado ‚úÖ
- Sistema de indexaci√≥n con ChromaDB
- Integraci√≥n completa con pipeline principal
- Normalizaci√≥n robusta de metadatos
- Tests unitarios completos
- Scripts de verificaci√≥n y actualizaci√≥n
- 125 documentos indexados exitosamente

### Resultados Obtenidos
- **Documentos Procesados**: 125/130 (96.2% cobertura)
- **Tasa de √âxito**: 100% en indexaci√≥n
- **Chunks Generados**: Variable seg√∫n complejidad del documento
- **Tiempo de Procesamiento**: Optimizado con cache
- **Calidad de Embeddings**: Compatible con modelo multiling√ºe

### En Desarrollo üîÑ
- Optimizaci√≥n de par√°metros para documentos complejos
- Mejoras en estrategias de indexaci√≥n
- Integraci√≥n con sistema de consultas

### Pendiente üìã
- Sistema de consultas sem√°nticas
- Evaluaci√≥n cualitativa de respuestas
- Optimizaci√≥n para consultas complejas
- Integraci√≥n con interfaz de usuario

## Configuraci√≥n de Producci√≥n

### Variables Cr√≠ticas
```python
# config/settings.py
CHROMA_PERSIST_DIRECTORY = "data/chroma_db"
CHROMA_COLLECTION_NAME = "legal_documents"
EMBEDDING_MODEL = "paraphrase-multilingual-mpnet-base-v2"
EMBEDDING_DIMENSIONS = 768
CSV_METADATA_PATH = "src/resources/metadata/pipeline_metadata.csv"
```

### Monitoreo
- Logs de indexaci√≥n en `logs/indexing.log`
- M√©tricas de rendimiento
- Verificaci√≥n de integridad de datos
- Alertas de errores cr√≠ticos

## Pr√≥ximos Pasos

### Paso 5: Sistema de Consultas
- Implementaci√≥n de b√∫squeda sem√°ntica
- Procesamiento de consultas naturales
- Generaci√≥n de respuestas con LLM
- Evaluaci√≥n de calidad de respuestas

### Integraci√≥n Completa
- Pipeline end-to-end funcional
- Sistema RAG completo para expedientes jur√≠dicos
- Interfaz de usuario para consultas
- Monitoreo y m√©tricas de producci√≥n 