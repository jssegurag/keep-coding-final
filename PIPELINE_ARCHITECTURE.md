# Arquitectura de Pipeline de Procesamiento de Documentos

## ğŸ—ï¸ Principios de DiseÃ±o

Este proyecto implementa una arquitectura de pipeline siguiendo los principios **SOLID** y **GRASP**:

### SOLID Principles
- **S** - Single Responsibility Principle (SRP): Cada clase tiene una Ãºnica responsabilidad
- **O** - Open/Closed Principle (OCP): Abierto para extensiÃ³n, cerrado para modificaciÃ³n
- **L** - Liskov Substitution Principle (LSP): Las implementaciones son intercambiables
- **I** - Interface Segregation Principle (ISP): Interfaces especÃ­ficas y cohesivas
- **D** - Dependency Inversion Principle (DIP): Depende de abstracciones, no de implementaciones

### GRASP Patterns
- **High Cohesion**: Responsabilidades relacionadas estÃ¡n agrupadas
- **Low Coupling**: MÃ­nima dependencia entre componentes
- **Information Expert**: Cada clase maneja su propia informaciÃ³n
- **Creator**: Clases responsables de crear instancias
- **Controller**: CoordinaciÃ³n centralizada

## ğŸ“ Estructura del Proyecto

```
src/
â”œâ”€â”€ domain/                           # Capa de dominio (interfaces)
â”‚   â”œâ”€â”€ i_pipeline_step.py           # Interfaz para pasos del pipeline
â”‚   â”œâ”€â”€ i_document_processor.py      # Interfaz para procesamiento
â”‚   â””â”€â”€ i_file_handler.py            # Interfaz para manejo de archivos
â”œâ”€â”€ infrastructure/                   # Capa de infraestructura (implementaciones)
â”‚   â”œâ”€â”€ pipeline_steps/              # Pasos del pipeline
â”‚   â”‚   â”œâ”€â”€ ocr_step.py             # Paso de OCR
â”‚   â”‚   â””â”€â”€ metadata_extraction_step.py # Paso de metadata
â”‚   â”œâ”€â”€ pipeline_config.py           # ConfiguraciÃ³n del pipeline
â”‚   â”œâ”€â”€ docling_api_processor.py     # Procesador de API
â”‚   â””â”€â”€ local_file_handler.py        # Manejador de archivos
â”œâ”€â”€ application/                      # Capa de aplicaciÃ³n (orquestaciÃ³n)
â”‚   â””â”€â”€ document_pipeline_orchestrator.py # Orquestador principal
â””â”€â”€ main.py                          # Punto de entrada
```

## ğŸ”„ Flujo del Pipeline

### 1. ConfiguraciÃ³n
```python
# ValidaciÃ³n de configuraciÃ³n
api_base_url, config = validate_configuration()

# CreaciÃ³n de componentes
file_handler = LocalFileHandler(source_dir=config.source_directory, target_dir=config.target_directory)
pipeline_steps = create_pipeline_steps(api_base_url, config)
```

### 2. OrquestaciÃ³n
```python
# Orquestador principal
orchestrator = DocumentPipelineOrchestrator(
    file_handler=file_handler,
    pipeline_steps=pipeline_steps,
    max_workers=config.max_workers
)

# EjecuciÃ³n del pipeline
orchestrator.execute_pipeline(output_formats=config.output_formats)
```

### 3. EjecuciÃ³n de Pasos
Cada documento pasa por los siguientes pasos en secuencia:

1. **OCR Step**: ExtracciÃ³n de texto mediante Docling API
2. **Metadata Extraction Step**: ExtracciÃ³n de metadata del archivo y contenido
3. **Future Steps**: Pasos adicionales configurables

## ğŸ§© Componentes Principales

### IPipelineStep (Interfaz)
```python
class IPipelineStep(ABC):
    @abstractmethod
    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        pass
    
    @abstractmethod
    def get_step_name(self) -> str:
        pass
    
    @abstractmethod
    def can_execute(self, input_data: Dict[str, Any]) -> bool:
        pass
```

**Principios aplicados:**
- **SRP**: Define solo el contrato para pasos del pipeline
- **ISP**: Interfaz especÃ­fica y cohesiva
- **DIP**: Dependencia de abstracciÃ³n, no implementaciÃ³n

### OCRStep (ImplementaciÃ³n)
```python
class OCRStep(IPipelineStep):
    def __init__(self, document_processor: DoclingApiProcessor):
        self.document_processor = document_processor  # InyecciÃ³n de dependencia
```

**Principios aplicados:**
- **SRP**: Solo se encarga del OCR
- **DIP**: Recibe dependencia inyectada
- **LSP**: Implementa correctamente la interfaz

### DocumentPipelineOrchestrator
```python
class DocumentPipelineOrchestrator:
    def __init__(self, file_handler: IFileHandler, pipeline_steps: List[IPipelineStep], max_workers: int):
        # InyecciÃ³n de dependencias
```

**Principios aplicados:**
- **SRP**: Solo orquesta la ejecuciÃ³n
- **High Cohesion**: Todas las responsabilidades estÃ¡n relacionadas
- **Low Coupling**: Depende de interfaces, no implementaciones

### PipelineConfig
```python
@dataclass
class PipelineConfig:
    # ConfiguraciÃ³n centralizada
    enable_ocr: bool = True
    enable_metadata_extraction: bool = True
    # ...
```

**Principios aplicados:**
- **SRP**: Solo maneja configuraciÃ³n
- **Information Expert**: Centraliza informaciÃ³n de configuraciÃ³n
- **Creator**: Factory method para crear configuraciones

## ğŸ”§ Extensibilidad

### Agregar Nuevos Pasos

1. **Crear nueva implementaciÃ³n**:
```python
class NewStep(IPipelineStep):
    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        # LÃ³gica del nuevo paso
        return enriched_data
```

2. **Actualizar configuraciÃ³n**:
```python
@dataclass
class PipelineConfig:
    enable_new_step: bool = False  # Nueva opciÃ³n
```

3. **Actualizar factory method**:
```python
def create_pipeline_steps(api_base_url: str, config: PipelineConfig) -> list:
    # ...
    if config.enable_new_step:
        pipeline_steps.append(NewStep())
    return pipeline_steps
```

### ConfiguraciÃ³n por Variables de Entorno

```env
API_BASE_URL=http://localhost:8000
MAX_WORKERS=10
SOURCE_DIR=src/resources/docs
TARGET_DIR=target
OUTPUT_FORMATS=json,html,text
```

## ğŸ¯ Ventajas de la Arquitectura

### âœ… **Mantenibilidad**
- SeparaciÃ³n clara de responsabilidades
- CÃ³digo modular y reutilizable
- FÃ¡cil testing de componentes individuales

### âœ… **Extensibilidad**
- Nuevos pasos sin modificar cÃ³digo existente (OCP)
- ConfiguraciÃ³n flexible
- Plug-and-play de componentes

### âœ… **Testabilidad**
- InyecciÃ³n de dependencias
- Interfaces bien definidas
- Componentes aislados

### âœ… **Escalabilidad**
- Procesamiento paralelo
- ConfiguraciÃ³n de workers
- Pipeline configurable

### âœ… **Robustez**
- ValidaciÃ³n de entrada en cada paso
- Manejo de errores por paso
- Logging detallado

## ğŸš€ Uso

### EjecuciÃ³n BÃ¡sica
```bash
python -m src.main
```

### ConfiguraciÃ³n Personalizada
```python
config = PipelineConfig(
    enable_ocr=True,
    enable_metadata_extraction=True,
    enable_legal_reference_extraction=False,
    max_workers=5
)
```

### Monitoreo
El pipeline proporciona logging detallado:
```
ğŸ¯ Iniciando pipeline de procesamiento de documentos...
âš™ï¸ Pasos configurados: 2
   1. ocr_extraction: ExtracciÃ³n de texto mediante OCR usando Docling API
   2. metadata_extraction: ExtracciÃ³n de metadata del documento y contenido OCR
ğŸ“„ Documentos encontrados: 3
âš¡ Procesando con hasta 10 workers...
ğŸš€ Iniciando pipeline para: documento1.pdf
ğŸ“‹ Paso 1/2: ocr_extraction
ğŸ” [OCR] Procesando: documento1.pdf
âœ… [OCR] Completado: documento1.pdf
âœ… Paso 1 completado: ocr_extraction
ğŸ“‹ Paso 2/2: metadata_extraction
ğŸ“Š [Metadata] Extrayendo metadata de: documento1.pdf
âœ… [Metadata] Completado: documento1.pdf
âœ… Paso 2 completado: metadata_extraction
âœ… Completado: documento1.pdf
```

## ğŸ”® Futuras Extensiones

### Pasos Planificados
- **LegalReferenceExtractionStep**: ExtracciÃ³n de referencias legales
- **VectorizationStep**: VectorizaciÃ³n para bÃºsqueda semÃ¡ntica
- **DatabaseStorageStep**: Almacenamiento en base de datos
- **QualityValidationStep**: ValidaciÃ³n de calidad del OCR

### Mejoras ArquitectÃ³nicas
- **Plugin System**: Carga dinÃ¡mica de pasos
- **Configuration Management**: ConfiguraciÃ³n desde archivos YAML/JSON
- **Metrics Collection**: MÃ©tricas de rendimiento
- **Error Recovery**: RecuperaciÃ³n automÃ¡tica de errores

---

Esta arquitectura proporciona una base sÃ³lida y extensible para el procesamiento de documentos, siguiendo las mejores prÃ¡cticas de diseÃ±o de software. 