# Estrategia RAG para Documentos Jur√≠dicos con DoclingDocument JSON

## üìã √çndice

1. [An√°lisis del Contexto](#an√°lisis-del-contexto)
2. [Estrategia de Procesamiento](#estrategia-de-procesamiento)
3. [Arquitectura de Base de Datos Vectorial](#arquitectura-de-base-de-datos-vectorial)
4. [Estrategias de Vectorizaci√≥n](#estrategias-de-vectorizaci√≥n)
5. [Estrategias de Retrieval](#estrategias-de-retrieval)
6. [Implementaci√≥n Pr√°ctica](#implementaci√≥n-pr√°ctica)
7. [Casos de Uso Espec√≠ficos](#casos-de-uso-espec√≠ficos)
8. [Consideraciones de Rendimiento](#consideraciones-de-rendimiento)

## üéØ An√°lisis del Contexto

### Caracter√≠sticas Espec√≠ficas de Documentos Jur√≠dicos

Los documentos jur√≠dicos presentan caracter√≠sticas √∫nicas que requieren un procesamiento especializado:

#### **Estructura Jer√°rquica Compleja:**
- **Encabezados**: T√≠tulos, subt√≠tulos, secciones, art√≠culos
- **Referencias Cruzadas**: Citas legales, n√∫meros de expediente
- **Metadata Jur√≠dica**: Fechas, jurisdicciones, autoridades
- **Elementos Visuales**: Firmas, sellos, logos institucionales

#### **Tablas Variables:**
- **Tama√±os Din√°micos**: Desde tablas peque√±as hasta complejas
- **Informaci√≥n Cr√≠tica**: Fechas, montos, referencias legales
- **Relaciones Estructurales**: Headers, celdas combinadas, spans

#### **Informaci√≥n Contextual:**
- **Referencias Legales**: Art√≠culos, leyes, decretos
- **Procedimientos**: N√∫meros de radicaci√≥n, expedientes
- **Temporalidad**: Fechas de presentaci√≥n, vencimientos

### An√°lisis del JSON de DoclingDocument

Bas√°ndonos en el an√°lisis de la estructura JSON, identificamos:

#### **Elementos Disponibles:**
- **Texts**: 20-66 elementos por documento con labels espec√≠ficos
- **Tables**: 0-4 elementos con estructura compleja de grid
- **Pictures**: 3-10 elementos con OCR integrado
- **Groups**: 0-5 elementos (key_value_area, form_area, list)

#### **Informaci√≥n de Coordenadas:**
- **Sistema**: BOTTOMLEFT con coordenadas precisas
- **Provenance**: Informaci√≥n de p√°gina y bounding boxes
- **Relaciones**: Referencias JSON entre elementos

## üèóÔ∏è Estrategia de Procesamiento

### Fase 1: Extracci√≥n Estructurada

#### **A. Procesamiento por Tipo de Elemento**

```python
class LegalDocumentProcessor:
    def process_docling_json(self, json_data):
        chunks = []
        
        # 1. Procesar textos con contexto jur√≠dico
        text_chunks = self.process_legal_texts(json_data['texts'])
        chunks.extend(text_chunks)
        
        # 2. Procesar tablas preservando estructura
        table_chunks = self.process_legal_tables(json_data['tables'])
        chunks.extend(table_chunks)
        
        # 3. Procesar im√°genes con OCR
        image_chunks = self.process_legal_images(json_data['pictures'])
        chunks.extend(image_chunks)
        
        # 4. Procesar grupos estructurados
        group_chunks = self.process_legal_groups(json_data['groups'])
        chunks.extend(group_chunks)
        
        return chunks
```

#### **B. Chunking Inteligente**

```python
class IntelligentLegalChunker:
    def chunk_by_type(self, element):
        if element['type'] == 'header':
            return self.create_header_chunk(element)
        elif element['type'] == 'table':
            return self.create_table_chunk(element)
        elif element['type'] == 'text':
            return self.sentence_based_chunking(element)
        elif element['type'] == 'image':
            return self.create_image_chunk(element)
```

### Fase 2: Enriquecimiento Contextual

#### **A. Metadata Jur√≠dica Espec√≠fica**

```python
def extract_legal_metadata(text):
    metadata = {
        'document_type': 'legal_document',
        'jurisdiction': 'colombia',
        'expedient_number': extract_expedient_number(text),
        'date': extract_date(text),
        'authority': extract_authority(text),
        'legal_references': extract_legal_citations(text),
        'confidence_score': calculate_ocr_confidence(text)
    }
    return metadata
```

#### **B. Contexto Jer√°rquico**

```python
def build_context_hierarchy(chunk):
    hierarchy = []
    
    # Agregar contexto de p√°gina
    hierarchy.append(f"p√°gina_{chunk.page_no}")
    
    # Agregar contexto de secci√≥n
    if chunk.parent_section:
        hierarchy.append(chunk.parent_section)
    
    # Agregar contexto de art√≠culo
    if chunk.parent_article:
        hierarchy.append(chunk.parent_article)
    
    return hierarchy
```

## üóÑÔ∏è Arquitectura de Base de Datos Vectorial

### Estructura del Documento Vectorial

```python
vector_document = {
    # Contenido principal
    "content": "texto del chunk...",
    "content_vector": [0.1, 0.2, 0.3, ...],
    
    # Metadata jur√≠dica
    "legal_metadata": {
        "document_type": "oficio_juridico",
        "expedient_number": "IQ051008152850",
        "jurisdiction": "colombia",
        "date": "2024-01-15",
        "authority": "tribunal_superior",
        "legal_references": ["art√≠culo 123", "ley 1234"],
        "confidence_score": 0.95
    },
    
    # Informaci√≥n estructural
    "structural_metadata": {
        "chunk_type": "text|table|header|image",
        "page_number": 1,
        "bbox": {"l": 100, "t": 200, "r": 300, "b": 250},
        "context_hierarchy": ["t√≠tulo", "secci√≥n", "art√≠culo"],
        "parent_chunk_id": "chunk_123"
    },
    
    # Informaci√≥n de b√∫squeda
    "search_metadata": {
        "keywords": ["expediente", "radicaci√≥n", "fecha"],
        "semantic_tags": ["procedimiento", "administrativo"],
        "cross_references": ["chunk_456", "chunk_789"]
    }
}
```

### Estrategias de Indexaci√≥n

#### **A. √çndices M√∫ltiples**

```python
# 1. √çndice sem√°ntico principal
semantic_index = create_vector_index(
    vectors=content_vectors,
    similarity_metric='cosine'
)

# 2. √çndice de metadata
metadata_index = create_vector_index(
    vectors=metadata_vectors,
    similarity_metric='cosine'
)

# 3. √çndice h√≠brido
hybrid_index = create_hybrid_index(
    vector_queries=content_vectors,
    keyword_queries=legal_keywords,
    weight_vector=0.7,
    weight_keyword=0.3
)
```

#### **B. Particionamiento por Tipo**

```python
# Separar chunks por tipo para b√∫squedas especializadas
indexes = {
    'text_chunks': create_index(text_chunks),
    'table_chunks': create_index(table_chunks),
    'header_chunks': create_index(header_chunks),
    'image_chunks': create_index(image_chunks)
}
```

## üîÑ Estrategias de Vectorizaci√≥n

### Vectorizaci√≥n M√∫ltiple

```python
def create_legal_vectors(chunk):
    vectors = {}
    
    # 1. Vector del contenido principal
    vectors['content_vector'] = embed_text(chunk.content)
    
    # 2. Vector de metadata jur√≠dica
    legal_text = f"{chunk.metadata['document_type']} {chunk.metadata['jurisdiction']} {chunk.metadata['expedient_number']}"
    vectors['metadata_vector'] = embed_text(legal_text)
    
    # 3. Vector de contexto estructural
    context_text = " ".join(chunk.context_hierarchy)
    vectors['context_vector'] = embed_text(context_text)
    
    # 4. Vector combinado (para b√∫squeda h√≠brida)
    combined_text = f"{chunk.content} {legal_text} {context_text}"
    vectors['combined_vector'] = embed_text(combined_text)
    
    return vectors
```

### Modelos de Embedding Especializados

```python
# Para documentos jur√≠dicos, usar modelos especializados
legal_embedding_models = {
    'content': 'sentence-transformers/all-MiniLM-L6-v2',
    'legal': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
    'spanish_legal': 'dccuchile/bert-base-spanish-wwm-cased'
}
```

## üîç Estrategias de Retrieval

### B√∫squeda H√≠brida

```python
def legal_document_search(query, filters=None):
    results = []
    
    # 1. B√∫squeda sem√°ntica
    semantic_results = semantic_index.search(
        query_vector=embed_query(query),
        top_k=10
    )
    
    # 2. B√∫squeda por metadata
    metadata_results = metadata_index.search(
        query_vector=embed_query(query),
        filters=filters,  # Expediente, fecha, jurisdicci√≥n
        top_k=5
    )
    
    # 3. B√∫squeda por keywords
    keyword_results = keyword_index.search(
        query=extract_legal_keywords(query),
        top_k=5
    )
    
    # 4. Combinar y re-rank
    combined_results = combine_and_rerank(
        semantic_results, metadata_results, keyword_results
    )
    
    return combined_results
```

### B√∫squeda Contextual

```python
def contextual_legal_search(query, context_chunk_id=None):
    # Si tenemos contexto previo, buscar chunks relacionados
    if context_chunk_id:
        related_chunks = find_related_chunks(context_chunk_id)
        context_query = f"{query} {related_chunks}"
    else:
        context_query = query
    
    return semantic_index.search(context_query)
```

## üõ†Ô∏è Implementaci√≥n Pr√°ctica

### Con Pinecone

```python
import pinecone

# Configurar Pinecone
pinecone.init(api_key="your_key", environment="your_env")
index_name = "legal-documents"

# Crear √≠ndice
pinecone.create_index(
    name=index_name,
    dimension=384,  # Dimensi√≥n del embedding
    metric="cosine"
)

# Insertar chunks
index = pinecone.Index(index_name)
index.upsert(vectors=legal_chunks_with_vectors)
```

### Con ChromaDB

```python
import chromadb

# Crear cliente
client = chromadb.Client()

# Crear colecci√≥n
collection = client.create_collection(
    name="legal_documents",
    metadata={"hnsw:space": "cosine"}
)

# Insertar documentos
collection.add(
    documents=[chunk.content for chunk in chunks],
    metadatas=[chunk.metadata for chunk in chunks],
    embeddings=[chunk.vector for chunk in chunks],
    ids=[chunk.id for chunk in chunks]
)
```

## üìä Casos de Uso Espec√≠ficos

### B√∫squeda por Expediente

```python
# Buscar todos los chunks de un expediente espec√≠fico
results = vector_db.search(
    query="expediente IQ051008152850",
    filter={"expedient_number": "IQ051008152850"}
)
```

### B√∫squeda por Referencia Legal

```python
# Buscar chunks que mencionen una ley espec√≠fica
results = vector_db.search(
    query="art√≠culo 123 c√≥digo civil",
    filter={"legal_references": {"$contains": "art√≠culo 123"}}
)
```

### B√∫squeda por Fecha

```python
# Buscar documentos de un per√≠odo espec√≠fico
results = vector_db.search(
    query="procedimiento administrativo",
    filter={"date": {"$gte": "2024-01-01", "$lte": "2024-12-31"}}
)
```

### B√∫squeda por Tipo de Documento

```python
# Buscar solo tablas o headers
results = vector_db.search(
    query="informaci√≥n de radicaci√≥n",
    filter={"chunk_type": "table"}
)
```

## ‚ö° Consideraciones de Rendimiento

### Optimizaci√≥n de Chunks

#### **A. Tama√±o √ìptimo de Chunks:**
- **Textos**: 500-1000 tokens
- **Tablas**: Chunk √∫nico por tabla
- **Headers**: Chunks separados
- **Im√°genes**: Chunk √∫nico con OCR

#### **B. Estrategias de Caching:**
```python
# Cache de embeddings
embedding_cache = {}

def get_cached_embedding(text, model_name):
    cache_key = f"{hash(text)}_{model_name}"
    if cache_key not in embedding_cache:
        embedding_cache[cache_key] = embed_text(text, model_name)
    return embedding_cache[cache_key]
```

#### **C. Procesamiento por Lotes:**
```python
def batch_process_chunks(chunks, batch_size=100):
    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i + batch_size]
        vectors = embed_batch(batch)
        insert_batch_to_vector_db(batch, vectors)
```

### Monitoreo y M√©tricas

#### **A. M√©tricas de Calidad:**
- **Precisi√≥n de Retrieval**: % de chunks relevantes recuperados
- **Cobertura**: % de informaci√≥n jur√≠dica capturada
- **Latencia**: Tiempo de respuesta de b√∫squeda

#### **B. M√©tricas de Rendimiento:**
- **Throughput**: Chunks procesados por segundo
- **Uso de Memoria**: Consumo de recursos
- **Tiempo de Indexaci√≥n**: Velocidad de inserci√≥n

## üéØ Ventajas de esta Estrategia

### ‚úÖ Preservaci√≥n de Estructura Jur√≠dica
- Encabezados como chunks separados
- Tablas con estructura preservada
- Jerarqu√≠a de contexto mantenida

### ‚úÖ Metadata Enriquecida
- Informaci√≥n jur√≠dica espec√≠fica
- Referencias cruzadas
- Confianza del OCR

### ‚úÖ Optimizaci√≥n para B√∫squeda
- Chunks sem√°nticamente coherentes
- Contexto preservado
- Relaciones entre elementos

### ‚úÖ Escalabilidad
- Procesamiento por lotes
- Metadata consistente
- F√°cil integraci√≥n con sistemas RAG

## üìà Implementaci√≥n en Fases

### Fase 1: Procesamiento B√°sico
- [ ] Implementar procesador de JSON DoclingDocument
- [ ] Crear chunking b√°sico por tipo de elemento
- [ ] Extraer metadata jur√≠dica b√°sica

### Fase 2: Enriquecimiento Avanzado
- [ ] Implementar extracci√≥n de referencias legales
- [ ] Crear sistema de contexto jer√°rquico
- [ ] Desarrollar vectorizaci√≥n m√∫ltiple

### Fase 3: Base de Datos Vectorial
- [ ] Configurar √≠ndices m√∫ltiples
- [ ] Implementar b√∫squeda h√≠brida
- [ ] Optimizar rendimiento

### Fase 4: Integraci√≥n RAG
- [ ] Conectar con sistema de generaci√≥n
- [ ] Implementar re-ranking
- [ ] Monitoreo y m√©tricas

---

**Nota**: Esta estrategia est√° dise√±ada espec√≠ficamente para documentos jur√≠dicos colombianos procesados con DoclingDocument JSON, optimizando tanto la precisi√≥n como el rendimiento para casos de uso legales espec√≠ficos.
