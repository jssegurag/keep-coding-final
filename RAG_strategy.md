# Estrategia RAG para Sistema de Expedientes Jur√≠dicos - MVP Blindado

## 1. Arquitectura de Indexaci√≥n - MVP Blindado

### 1.1 Stack Tecnol√≥gico para MVP

**Arquitectura Simplificada: ChromaDB + SQLite + Gemini 2.0 Flash Lite**

#### Componentes Principales:
- **ChromaDB**: Base de datos vectorial + metadatos filtrables
- **SQLite**: Base de datos relacional para metadatos can√≥nicos
- **Gemini 2.0 Flash Lite**: LLM para generaci√≥n de respuestas

#### Justificaci√≥n de la Simplificaci√≥n:

1. **Eliminaci√≥n de Complejidad Innecesaria**: 
   - Un solo motor de b√∫squeda vectorial con filtrado nativo
   - Sin enrutamiento complejo de consultas
   - Flujo √∫nico y robusto

2. **Optimizaci√≥n para MVP**: 
   - ChromaDB maneja tanto vectores como filtrado de metadatos
   - SQLite solo para datos de referencia
   - Respuestas r√°pidas y precisas

3. **Escalabilidad Futura**: 
   - F√°cil migraci√≥n a arquitectura h√≠brida completa
   - Base s√≥lida para iteraciones

### 1.2 Estrategia de Chunking - CR√çTICA PARA MVP

#### Implementaci√≥n Obligatoria de Chunking:

**Problema Identificado**: Un embedding por documento completo es in√∫til para RAG efectivo.

**Soluci√≥n MVP**:
- **Tama√±o de Chunk**: 512 tokens con overlap de 50 tokens
- **Estrategia**: Divisi√≥n por p√°rrafos naturales + l√≠mite de tokens
- **Metadatos por Chunk**: ID documento padre + posici√≥n + metadatos relevantes

#### Estructura de Chunking:
```
Documento RCCI2150725310
‚îú‚îÄ‚îÄ Chunk 1: [0-512 tokens] - Encabezado y datos b√°sicos
‚îú‚îÄ‚îÄ Chunk 2: [462-974 tokens] - Demandante y demandado
‚îú‚îÄ‚îÄ Chunk 3: [924-1436 tokens] - Hechos principales
‚îú‚îÄ‚îÄ Chunk 4: [1386-1898 tokens] - Medidas cautelares
‚îî‚îÄ‚îÄ Chunk N: [√∫ltimos tokens] - Firmas y conclusiones
```

#### Metadatos por Chunk:
```json
{
  "document_id": "RCCI2150725310",
  "chunk_id": "RCCI2150725310_chunk_1",
  "chunk_position": 1,
  "total_chunks": 5,
  "demandante": "NURY WILLELMA ROMERO GOMEZ",
  "demandado": "MUNICIPIO DE ARAUCA",
  "tipo_medida": "Embargo",
  "entidad": "MUNICIPIO DE ARAUCA",
  "fecha": "2025-07-14",
  "cuantia": "238.984.000,00"
}
```

### 1.3 Flujo de Consulta Simplificado - MVP

#### Eliminaci√≥n del Enrutador Complejo:

**Problema Identificado**: Clasificaci√≥n de consultas a√±ade complejidad innecesaria.

**Soluci√≥n MVP - Flujo √önico**:
1. **Extracci√≥n de Filtros**: Extraer entidades de la consulta (nombres, fechas, n√∫meros)
2. **B√∫squeda H√≠brida Simplificada**:
   - Filtrar chunks en ChromaDB por metadatos
   - B√∫squeda vectorial en chunks filtrados
3. **Recuperaci√≥n de Contexto**: Top-k chunks m√°s relevantes
4. **Generaci√≥n con LLM**: Prompt √∫nico que maneja todos los tipos de consulta

#### Prompt √önico para Gemini con Instrucciones Estructuradas:
```
Contexto: {chunks_recuperados}

Pregunta del usuario: {consulta_original}

Instrucciones espec√≠ficas:
- Si la pregunta busca un resumen, genera un resumen estructurado del expediente
- Si la pregunta es espec√≠fica sobre contenido, responde bas√°ndote √∫nicamente en el contexto proporcionado
- Si la pregunta es sobre metadatos (fechas, nombres, cuant√≠as), extrae la informaci√≥n relevante
- Si la informaci√≥n no est√° en el contexto, responde: "No se encuentra en el expediente proporcionado."
- Responde en espa√±ol de manera profesional y jur√≠dica
- Al final de cada respuesta, incluye: "Fuente: {document_id}, Chunk {chunk_position} de {total_chunks}"

Tareas posibles:
- Resumir el contenido legal
- Responder preguntas espec√≠ficas del contenido
- Extraer campos clave como fechas, cuant√≠as o nombres
- Identificar tipos de medidas cautelares
```

## 2. Flujo de Datos Simplificado - MVP

### 2.1 Proceso de Ingesta con Chunking

#### Fase 1: Extracci√≥n y Chunking
1. **Lectura de Datos**
   - Leer CSV de metadatos
   - Extraer texto completo de JSON de Docling
   - Parsear metadatos estructurados

2. **Chunking Obligatorio**
   - Dividir texto en chunks de 512 tokens
   - Overlap de 50 tokens entre chunks
   - Preservar estructura sem√°ntica (p√°rrafos)
   - **Fallback recursivo**: Si un p√°rrafo excede 512 tokens, dividir por oraciones

3. **Preparaci√≥n de Metadatos**
   - Asignar metadatos a cada chunk
   - Generar IDs √∫nicos por chunk
   - Validar integridad de datos

#### Fase 2: Indexaci√≥n Simplificada
1. **Indexaci√≥n en ChromaDB**
   - Generar embedding por chunk
   - Almacenar metadatos filtrables
   - Asociar con ID del documento padre

2. **Base de Datos de Referencia**
   - SQLite solo para metadatos can√≥nicos
   - Relaciones documento-chunks
   - Estad√≠sticas de indexaci√≥n

### 2.2 Flujo de Consulta - MVP Blindado

#### Eliminaci√≥n del Enrutador:
**Antes (Complejo)**:
```
Consulta ‚Üí Clasificador ‚Üí Enrutador ‚Üí Motor espec√≠fico ‚Üí Respuesta
```

**Ahora (Simple)**:
```
Consulta ‚Üí Extracci√≥n filtros ‚Üí B√∫squeda h√≠brida ‚Üí LLM ‚Üí Respuesta
```

#### Proceso Detallado:

1. **Extracci√≥n de Filtros Mejorada**
   - **Normalizaci√≥n de nombres**: Convertir a min√∫scula, sin tildes
   - **B√∫squeda parcial**: Usar LIKE para nombres similares
   - **Patrones de fechas**: Detectar formatos DD/MM/YYYY, YYYY-MM-DD
   - **N√∫meros y cuant√≠as**: Extraer valores monetarios
   - **T√©rminos jur√≠dicos**: Detectar tipos de medidas cautelares

2. **B√∫squeda H√≠brida en ChromaDB**
   ```python
   # Pseudoc√≥digo con tolerancia mejorada
   normalized_filters = normalize_filters(extracted_filters)
   filtered_chunks = chroma_collection.query(
       query_texts=[user_query],
       where=normalized_filters,
       n_results=10
   )
   ```

3. **Generaci√≥n con Gemini**
   - Construir prompt con contexto y instrucciones estructuradas
   - Dejar que Gemini interprete la intenci√≥n
   - Generar respuesta apropiada con trazabilidad

## 3. Especificaciones de Dise√±o - MVP Blindado

### 3.1 Estructura de Datos Simplificada

#### Chunk en ChromaDB:
```json
{
  "id": "RCCI2150725310_chunk_1",
  "embedding": [vector_512_dimensions],
  "text": "Texto del chunk...",
  "metadata": {
    "document_id": "RCCI2150725310",
    "chunk_position": 1,
    "demandante": "NURY WILLELMA ROMERO GOMEZ",
    "demandado": "MUNICIPIO DE ARAUCA",
    "tipo_medida": "Embargo",
    "entidad": "MUNICIPIO DE ARAUCA",
    "fecha": "2025-07-14",
    "cuantia": "238.984.000,00",
    "demandante_normalized": "nury willelma romero gomez",
    "demandado_normalized": "municipio de arauca"
  }
}
```

#### Documento en SQLite (Referencia):
```sql
CREATE TABLE documents (
    id TEXT PRIMARY KEY,
    filename TEXT,
    total_chunks INTEGER,
    indexed_at TIMESTAMP,
    metadata_json TEXT
);
```

### 3.2 Configuraci√≥n de B√∫squeda - MVP Blindado

#### ChromaDB:
- **Dimensiones**: 512 (sentence-transformers)
- **Distancia**: Coseno
- **Filtrado**: Metadatos nativos con normalizaci√≥n
- **Resultados**: Top-10 chunks

#### SQLite:
- **B√∫squeda**: Solo para estad√≠sticas
- **Relaciones**: Documento-chunks
- **Backup**: Metadatos can√≥nicos

## 4. Validaci√≥n y Testing - MVP Blindado

### 4.1 Validaci√≥n de Embeddings para Textos Legales

#### Prueba Previa de Embeddings:
**Antes de indexar todo el corpus**:
1. **Seleccionar 5 documentos representativos** con diferentes tipos de contenido legal
2. **Crear 10 preguntas de prueba** que cubran diferentes aspectos (nombres, fechas, cuant√≠as, tipos de medida)
3. **Generar embeddings** con `paraphrase-multilingual-mpnet-base-v2`
4. **Comparar resultados** con b√∫squedas manuales esperadas
5. **Si la precisi√≥n es < 70%**, considerar alternativas como `all-MiniLM-L6-v2` o `distiluse-base-multilingual-cased-v2`

#### Criterios de Validaci√≥n:
- [ ] Embeddings capturan similitud sem√°ntica en textos legales
- [ ] B√∫squedas por nombres devuelven resultados relevantes
- [ ] B√∫squedas por conceptos jur√≠dicos funcionan correctamente

### 4.2 Testing Unitario para Chunking y B√∫squeda

#### Archivo de Testing: `run_test_set.py`
```python
# Pseudoc√≥digo para testing
def test_chunking_and_search():
    # 1. Documentos de prueba
    test_docs = load_test_documents()
    
    # 2. Preguntas de prueba con respuestas esperadas
    test_questions = [
        ("¬øCu√°l es el demandante?", "NURY WILLELMA ROMERO GOMEZ"),
        ("¬øCu√°l es la cuant√≠a?", "238.984.000,00"),
        ("¬øQu√© tipo de medida es?", "Embargo")
    ]
    
    # 3. Ejecutar chunking y b√∫squeda
    for doc in test_docs:
        chunks = chunk_document(doc)
        for question, expected in test_questions:
            result = search_and_answer(question, chunks)
            assert expected in result
```

#### M√©tricas de Testing:
- **Recall@k**: Medir cu√°ntos chunks relevantes se recuperan
- **Precisi√≥n**: Verificar que los chunks recuperados contienen la informaci√≥n buscada
- **Tiempo de respuesta**: < 3 segundos por consulta

### 4.3 Evaluaci√≥n Cualitativa con 20 Preguntas

#### Set de Preguntas Representativas:
1. **Preguntas de metadatos** (5 preguntas):
   - "¬øCu√°l es el demandante del expediente RCCI2150725310?"
   - "¬øCu√°l es la cuant√≠a del embargo?"
   - "¬øEn qu√© fecha se dict√≥ la medida?"

2. **Preguntas de contenido** (10 preguntas):
   - "¬øCu√°les son los hechos principales del caso?"
   - "¬øQu√© fundamentos jur√≠dicos se esgrimen?"
   - "¬øCu√°les son las medidas cautelares solicitadas?"

3. **Preguntas de resumen** (5 preguntas):
   - "Resume el expediente RCCI2150725310"
   - "¬øCu√°l es el estado actual del proceso?"

#### Escala de Evaluaci√≥n:
- **Correcta**: Respuesta precisa y completa
- **Parcialmente Correcta**: Respuesta con informaci√≥n relevante pero incompleta
- **Incorrecta**: Respuesta err√≥nea o sin informaci√≥n √∫til

**Objetivo MVP**: > 80% de respuestas en categor√≠as "Correcta" o "Parcialmente Correcta"

## 5. Plan de Implementaci√≥n - MVP Blindado

### 5.1 Fase 1: Validaci√≥n de Embeddings y Pipeline End-to-End

#### Objetivo Principal:
**Validar que el sistema RAG funciona de extremo a extremo con embeddings apropiados**

#### Tareas Cr√≠ticas:

1. **Validaci√≥n de Embeddings**
   - Probar `paraphrase-multilingual-mpnet-base-v2` con 5 documentos
   - Crear y ejecutar 10 preguntas de prueba
   - Si no funciona bien, probar alternativas

2. **Implementar Chunking con Fallback**
   - Funci√≥n de divisi√≥n de texto en chunks
   - Preservaci√≥n de metadatos por chunk
   - Fallback recursivo para chunks grandes
   - Validaci√≥n de integridad

3. **Indexaci√≥n en ChromaDB con Normalizaci√≥n**
   - Generaci√≥n de embeddings por chunk
   - Almacenamiento con metadatos normalizados
   - Validaci√≥n de indexaci√≥n

4. **Flujo de Consulta √önico con Trazabilidad**
   - Extracci√≥n de filtros mejorada
   - B√∫squeda h√≠brida en ChromaDB
   - Integraci√≥n con Gemini
   - Inclusi√≥n de fuente en respuestas

5. **Testing Unitario**
   - Implementar `run_test_set.py`
   - Validar chunking y b√∫squeda
   - Medir Recall@k y precisi√≥n

#### Criterios de √âxito Fase 1:
- [ ] Embeddings validados para textos legales
- [ ] Chunking funcional con fallback
- [ ] B√∫squeda h√≠brida operativa
- [ ] Integraci√≥n con Gemini funcionando
- [ ] Testing unitario pasando
- [ ] Trazabilidad en respuestas

### 5.2 Fase 2: Optimizaci√≥n y Evaluaci√≥n Cualitativa

#### Objetivo:
**Mejorar precisi√≥n y validar con preguntas reales**

#### Tareas:
1. **Optimizar Chunking**
   - Ajustar tama√±o de chunks basado en resultados
   - Mejorar estrategia de divisi√≥n
   - Optimizar overlap

2. **Mejorar Prompts**
   - Refinar prompt √∫nico con instrucciones estructuradas
   - A√±adir ejemplos espec√≠ficos para textos legales
   - Optimizar para diferentes tipos de consulta

3. **Evaluaci√≥n Cualitativa**
   - Ejecutar 20 preguntas representativas
   - Evaluar respuestas seg√∫n escala definida
   - Ajustar sistema basado en resultados

### 5.3 Fase 3: Escalabilidad y Monitoreo

#### Objetivo:
**Preparar para crecimiento y monitoreo**

#### Tareas:
1. **Monitoreo y M√©tricas**
   - Tiempo de respuesta
   - Precisi√≥n de respuestas
   - Uso de recursos

2. **Optimizaciones de Rendimiento**
   - Cach√© de consultas frecuentes
   - Compresi√≥n de embeddings
   - Indexaci√≥n incremental

## 6. Configuraci√≥n R√°pida para MVP Blindado

### 6.1 Stack Final Recomendado

**Herramientas Seleccionadas:**
- **ChromaDB**: Base vectorial + filtrado de metadatos
- **SQLite**: Base de datos de referencia
- **Google Gemini 2.0 Flash Lite**: LLM econ√≥mico
- **Sentence Transformers**: Embeddings de chunks

### 6.2 Instalaci√≥n y Configuraci√≥n

#### Dependencias:
```bash
pip install chromadb google-generativeai sentence-transformers pandas
```

#### Estructura de Archivos:
```
mvp/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ chroma_db/          # ChromaDB autom√°tico
‚îÇ   ‚îî‚îÄ‚îÄ legal_docs.db       # SQLite reference
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ chunker.py          # Funci√≥n de chunking con fallback
‚îÇ   ‚îú‚îÄ‚îÄ indexer.py          # Indexador con normalizaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ query_handler.py    # Manejador √∫nico con trazabilidad
‚îÇ   ‚îú‚îÄ‚îÄ test_set.py         # Testing unitario
‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ run_mvp.py
```

#### Configuraci√≥n M√≠nima:
```python
# config.py
GOOGLE_API_KEY = "tu-api-key"
CSV_PATH = "src/resources/metadata/studio_results_20250715_2237.csv"
TARGET_PATH = "target/"
CHUNK_SIZE = 512
CHUNK_OVERLAP = 50
EMBEDDING_MODEL = "paraphrase-multilingual-mpnet-base-v2"
```

### 6.3 Implementaci√≥n de Chunking con Fallback

#### Funci√≥n Cr√≠tica:
```python
def chunk_document(text, metadata, chunk_size=512, overlap=50):
    """
    Divide el texto en chunks con metadatos preservados
    Incluye fallback recursivo para chunks grandes
    """
    # Implementar l√≥gica de chunking
    # Preservar metadatos por chunk
    # Fallback recursivo por oraciones si es necesario
    # Generar IDs √∫nicos
    pass
```

### 6.4 Flujo de Consulta Blindado

#### Pseudoc√≥digo:
```python
def handle_query(query):
    # 1. Extraer filtros con normalizaci√≥n
    filters = extract_filters_with_normalization(query)
    
    # 2. B√∫squeda h√≠brida en ChromaDB
    results = chroma_collection.query(
        query_texts=[query],
        where=filters,
        n_results=10
    )
    
    # 3. Construir prompt con contexto y trazabilidad
    context = format_chunks(results['documents'])
    prompt = build_structured_prompt(context, query)
    
    # 4. Generar respuesta con Gemini
    response = gemini.generate(prompt)
    
    # 5. A√±adir informaci√≥n de fuente
    response += f"\n\nFuente: {document_id}, Chunk {chunk_position} de {total_chunks}"
    
    return response
```

## 7. Ventajas del MVP Blindado

### 7.1 Simplicidad:
- ‚úÖ **Un solo flujo de consulta** - Sin enrutamiento complejo
- ‚úÖ **Chunking desde el d√≠a 1** - Precisi√≥n garantizada
- ‚úÖ **ChromaDB como motor √∫nico** - Sin sincronizaci√≥n entre sistemas
- ‚úÖ **Prompt estructurado** - LLM maneja la interpretaci√≥n con instrucciones claras

### 7.2 Robustez:
- ‚úÖ **Validaci√≥n de embeddings** - Prueba previa con textos legales
- ‚úÖ **Normalizaci√≥n de filtros** - Tolerancia a variaciones en nombres
- ‚úÖ **Fallback recursivo** - Manejo de chunks grandes
- ‚úÖ **Trazabilidad** - Fuente visible en respuestas

### 7.3 Velocidad:
- ‚úÖ **MVP funcional r√°pidamente** - Validaci√≥n r√°pida
- ‚úÖ **Testing unitario** - Validaci√≥n autom√°tica
- ‚úÖ **Sin dependencias externas** - Despliegue inmediato
- ‚úÖ **Iteraci√≥n r√°pida** - F√°cil de mejorar

### 7.4 Escalabilidad:
- ‚úÖ **Base s√≥lida** - F√°cil migraci√≥n a arquitectura completa
- ‚úÖ **Chunking optimizable** - Mejoras incrementales
- ‚úÖ **Prompts refinables** - Ajustes espec√≠ficos

## 8. Aclaraciones y Decisiones Pendientes para el MVP Blindado

### 8.1 Estrategia para la Extracci√≥n de Filtros (`extract_filters()`)

**ü§î Cuestionamiento:** ¬øC√≥mo exactamente se traducir√° una consulta en lenguaje natural (ej: "embargos de Nury Romero") a un filtro de base de datos (`{"demandante": "Nury Romero", "tipo_medida": "Embargo"}`)?

**‚úÖ Aclaraci√≥n expl√≠cita para el plan:** Para el **MVP**, la funci√≥n `extract_filters()` se implementar√° con una estrategia simple basada en **palabras clave y expresiones regulares**. Se crear√°n patrones para detectar fechas, cuant√≠as y t√©rminos jur√≠dicos comunes (ej: "embargo", "demanda"). Para nombres propios, se usar√° una b√∫squeda de coincidencia parcial con **normalizaci√≥n** (min√∫scula, sin tildes). Se reconoce que este m√©todo es una simplificaci√≥n y su mejora ser√° un objetivo para futuras fases.

### 8.2 Manejo de "Chunks" de Gran Tama√±o

**ü§î Cuestionamiento:** ¬øQu√© pasar√° si un p√°rrafo individual dentro de un documento supera el tama√±o m√°ximo definido para un chunk (512 tokens)?

**‚úÖ Aclaraci√≥n expl√≠cita para el plan:** La estrategia de chunking debe incluir un **mecanismo de fallback recursivo**. Si un p√°rrafo excede el `CHUNK_SIZE`, ser√° dividido **recursivamente por oraciones**, hasta que todos los fragmentos resultantes est√©n por debajo del l√≠mite. Esto garantiza que no se pierda informaci√≥n por truncamiento.

### 8.3 Medici√≥n de Calidad y Precisi√≥n

**ü§î Cuestionamiento:** ¬øC√≥mo se medir√° de forma realista el criterio de √©xito de "Precisi√≥n > 80%" para el MVP?

**‚úÖ Aclaraci√≥n expl√≠cita para el plan:** Se reemplazar√° la m√©trica cuantitativa por una **evaluaci√≥n cualitativa**. Se definir√° un set de **20 preguntas de prueba representativas**. Las respuestas del sistema ser√°n evaluadas por un experto en el dominio bajo una escala simple (ej: Correcta, Parcialmente Correcta, Incorrecta). El objetivo del MVP es que la mayor√≠a de las respuestas caigan en las dos primeras categor√≠as.

### 8.4 Selecci√≥n del Modelo de Embeddings

**ü§î Cuestionamiento:** "Sentence Transformers" es una librer√≠a, ¬øqu√© modelo espec√≠fico se utilizar√° para generar los embeddings?

**‚úÖ Aclaraci√≥n expl√≠cita para el plan:** Para el MVP se utilizar√° el modelo `paraphrase-multilingual-mpnet-base-v2` por su balance entre rendimiento y soporte multiling√ºe, incluyendo el espa√±ol. **Antes de indexar todo el corpus**, se realizar√° una **validaci√≥n previa** con 5 documentos representativos y 10 preguntas de prueba para asegurar que el modelo funciona bien con textos legales colombianos. Si no cumple las expectativas, se evaluar√°n alternativas como `all-MiniLM-L6-v2` o `distiluse-base-multilingual-cased-v2`.

### 8.5 Trazabilidad de Respuestas

**ü§î Cuestionamiento:** ¬øC√≥mo se garantizar√° que las respuestas sean trazables a su fuente?

**‚úÖ Aclaraci√≥n expl√≠cita para el plan:** Cada respuesta generada por el sistema incluir√° al final la informaci√≥n de fuente en el formato: "Fuente: {document_id}, Chunk {chunk_position} de {total_chunks}". Esto proporciona trazabilidad m√≠nima sin implementar un motor de explicaci√≥n formal, permitiendo verificar de d√≥nde proviene la informaci√≥n.

## 9. Criterios de √âxito del MVP Blindado

### 9.1 Funcionalidad:
- [ ] Embeddings validados para textos legales
- [ ] Chunking funcional con fallback recursivo
- [ ] B√∫squeda h√≠brida operativa con normalizaci√≥n
- [ ] Respuestas coherentes a preguntas espec√≠ficas
- [ ] Integraci√≥n con Gemini funcionando
- [ ] Trazabilidad en respuestas

### 9.2 Rendimiento:
- [ ] Respuestas en menos de 3 segundos
- [ ] Evaluaci√≥n cualitativa con 20 preguntas de prueba
- [ ] Cobertura > 90% de documentos
- [ ] Testing unitario pasando

### 9.3 Escalabilidad:
- [ ] Capacidad para 1,000+ documentos
- [ ] F√°cil migraci√≥n a arquitectura completa
- [ ] Base para iteraciones futuras

Esta estrategia blindada aborda todos los puntos cr√≠ticos identificados y proporciona un MVP funcional, robusto y que valida la viabilidad del sistema RAG de extremo a extremo. Las aclaraciones anteriores eliminan las ambig√ºedades y establecen decisiones claras para el desarrollo, incluyendo validaci√≥n previa de embeddings, testing unitario y trazabilidad de respuestas.
