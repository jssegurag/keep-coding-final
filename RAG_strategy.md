# Estrategia RAG para Documentos Jur√≠dicos con DoclingDocument JSON

## üìã √çndice

1. [An√°lisis del Contexto](#an√°lisis-del-contexto)
2. [Estrategia de Procesamiento](#estrategia-de-procesamiento)
3. [Arquitectura de Base de Datos Vectorial](#arquitectura-de-base-de-datos-vectorial)
4. [Estrategias de Vectorizaci√≥n](#estrategias-de-vectorizaci√≥n)
5. [Estrategias de Retrieval](#estrategias-de-retrieval)
6. [Captura de Metadata Jur√≠dica](#captura-de-metadata-jur√≠dica)
7. [Implementaci√≥n Pr√°ctica](#implementaci√≥n-pr√°ctica)
8. [Casos de Uso Espec√≠ficos](#casos-de-uso-espec√≠ficos)
9. [Consideraciones de Rendimiento](#consideraciones-de-rendimiento)

## üéØ An√°lisis del Contexto

### Caracter√≠sticas Espec√≠ficas de Documentos Jur√≠dicos

Los documentos jur√≠dicos presentan caracter√≠sticas √∫nicas que requieren un procesamiento especializado:

#### **Estructura Jer√°rquica Compleja:**
- **Encabezados**: T√≠tulos, subt√≠tulos, secciones, art√≠culos
- **Referencias Cruzadas**: Citas legales, n√∫meros de expediente
- **Metadata Jur√≠dica**: Fechas, jurisdicciones, autoridades
- **Elementos Visuales**: Firmas, sellos, logos institucionales

#### **Tablas Variables:**
- **Tama√±os Din√°micos**: Desde tablas peque√±as hasta complejas
- **Informaci√≥n Cr√≠tica**: Fechas, montos, referencias legales
- **Relaciones Estructurales**: Headers, celdas combinadas, spans

#### **Informaci√≥n Contextual:**
- **Referencias Legales**: Art√≠culos, leyes, decretos
- **Procedimientos**: N√∫meros de radicaci√≥n, expedientes
- **Temporalidad**: Fechas de presentaci√≥n, vencimientos

### An√°lisis del JSON de DoclingDocument

Bas√°ndonos en el an√°lisis de la estructura JSON, identificamos:

#### **Elementos Disponibles:**
- **Texts**: 20-66 elementos por documento con labels espec√≠ficos
- **Tables**: 0-4 elementos con estructura compleja de grid
- **Pictures**: 3-10 elementos con OCR integrado
- **Groups**: 0-5 elementos (key_value_area, form_area, list)

#### **Informaci√≥n de Coordenadas:**
- **Sistema**: BOTTOMLEFT con coordenadas precisas
- **Provenance**: Informaci√≥n de p√°gina y bounding boxes
- **Relaciones**: Referencias JSON entre elementos

## üèóÔ∏è Estrategia de Procesamiento

### Fase 1: Extracci√≥n Estructurada

#### **A. Procesamiento por Tipo de Elemento**

```python
class LegalDocumentProcessor:
    def process_docling_json(self, json_data):
        chunks = []
        
        # 1. Procesar textos con contexto jur√≠dico
        text_chunks = self.process_legal_texts(json_data['texts'])
        chunks.extend(text_chunks)
        
        # 2. Procesar tablas preservando estructura
        table_chunks = self.process_legal_tables(json_data['tables'])
        chunks.extend(table_chunks)
        
        # 3. Procesar im√°genes con OCR
        image_chunks = self.process_legal_images(json_data['pictures'])
        chunks.extend(image_chunks)
        
        # 4. Procesar grupos estructurados
        group_chunks = self.process_legal_groups(json_data['groups'])
        chunks.extend(group_chunks)
        
        return chunks
```

#### **B. Chunking Inteligente**

```python
class IntelligentLegalChunker:
    def chunk_by_type(self, element):
        if element['type'] == 'header':
            return self.create_header_chunk(element)
        elif element['type'] == 'table':
            return self.create_table_chunk(element)
        elif element['type'] == 'text':
            return self.sentence_based_chunking(element)
        elif element['type'] == 'image':
            return self.create_image_chunk(element)
```

### Fase 2: Enriquecimiento Contextual

#### **A. Metadata Jur√≠dica Espec√≠fica**

```python
def extract_legal_metadata(text):
    metadata = {
        'document_type': 'legal_document',
        'jurisdiction': 'colombia',
        'expedient_number': extract_expedient_number(text),
        'date': extract_date(text),
        'authority': extract_authority(text),
        'legal_references': extract_legal_citations(text),
        'confidence_score': calculate_ocr_confidence(text)
    }
    return metadata
```

#### **B. Contexto Jer√°rquico**

```python
def build_context_hierarchy(chunk):
    hierarchy = []
    
    # Agregar contexto de p√°gina
    hierarchy.append(f"p√°gina_{chunk.page_no}")
    
    # Agregar contexto de secci√≥n
    if chunk.parent_section:
        hierarchy.append(chunk.parent_section)
    
    # Agregar contexto de art√≠culo
    if chunk.parent_article:
        hierarchy.append(chunk.parent_article)
    
    return hierarchy
```

## üîç Captura de Metadata Jur√≠dica

### Estrategia Multi-Fuente para Metadata

Cuando el OCR no es confiable, implementamos una estrategia de m√∫ltiples fuentes para capturar metadata jur√≠dica:

#### **A. Extracci√≥n Inteligente con Fallbacks**

```python
class LegalMetadataExtractor:
    def __init__(self):
        self.ocr_confidence_threshold = 0.7
        self.fallback_strategies = [
            self.extract_from_filename,
            self.extract_from_filepath,
            self.extract_from_document_structure,
            self.extract_from_visual_elements,
            self.extract_from_context_patterns
        ]
    
    def extract_metadata(self, docling_json, file_info):
        metadata = {
            'document_type': 'unknown',
            'expedient_number': None,
            'jurisdiction': 'colombia',  # Default
            'date': None,
            'authority': None,
            'legal_references': [],
            'confidence_score': 0.0,
            'extraction_method': 'unknown'
        }
        
        # Intentar extracci√≥n desde OCR primero
        ocr_metadata = self.extract_from_ocr(docling_json)
        if ocr_metadata['confidence_score'] >= self.ocr_confidence_threshold:
            metadata.update(ocr_metadata)
            metadata['extraction_method'] = 'ocr'
            return metadata
        
        # Aplicar estrategias de fallback
        for strategy in self.fallback_strategies:
            fallback_metadata = strategy(docling_json, file_info)
            if self.validate_metadata(fallback_metadata):
                metadata.update(fallback_metadata)
                metadata['extraction_method'] = strategy.__name__
                break
        
        return metadata
    
    def extract_from_filename(self, docling_json, file_info):
        """Extraer metadata desde el nombre del archivo"""
        filename = file_info['filename']
        
        # Patrones comunes en nombres de archivos jur√≠dicos
        patterns = {
            'expedient_number': r'IQ\d{12}',  # Patr√≥n de expedientes
            'date': r'(\d{4})[-_](\d{2})[-_](\d{2})',  # Fechas
            'document_type': r'(Judicial|Coactivo|Administrativo)',
            'authority': r'(Bog|Bar|Med|Cal)',  # C√≥digos de ciudades
        }
        
        metadata = {}
        for key, pattern in patterns.items():
            match = re.search(pattern, filename)
            if match:
                metadata[key] = match.group(0)
        
        return metadata
    
    def extract_from_filepath(self, docling_json, file_info):
        """Extraer metadata desde la estructura de carpetas"""
        filepath = file_info['filepath']
        
        # Analizar estructura de directorios
        path_parts = filepath.split('/')
        
        metadata = {}
        
        # Buscar patrones en la estructura de carpetas
        for part in path_parts:
            if 'Judicial' in part:
                metadata['document_type'] = 'judicial'
            elif 'Coactivo' in part:
                metadata['document_type'] = 'coactivo'
            elif 'Administrativo' in part:
                metadata['document_type'] = 'administrativo'
            
            # Buscar c√≥digos de expediente en carpetas
            expedient_match = re.search(r'IQ\d{12}', part)
            if expedient_match:
                metadata['expedient_number'] = expedient_match.group(0)
        
        return metadata
    
    def extract_from_document_structure(self, docling_json, file_info):
        """Extraer metadata desde la estructura del documento"""
        metadata = {}
        
        # Analizar elementos de texto con mayor confianza
        high_confidence_texts = [
            text for text in docling_json['texts']
            if text.get('confidence', 0) > 0.8
        ]
        
        # Buscar patrones en textos de alta confianza
        for text in high_confidence_texts:
            content = text.get('content', '')
            
            # Buscar expedientes
            expedient_match = re.search(r'IQ\d{12}', content)
            if expedient_match:
                metadata['expedient_number'] = expedient_match.group(0)
            
            # Buscar fechas
            date_match = re.search(r'\d{1,2}[/-]\d{1,2}[/-]\d{4}', content)
            if date_match:
                metadata['date'] = date_match.group(0)
            
            # Buscar autoridades
            authority_keywords = ['tribunal', 'juzgado', 'fiscal√≠a', 'procuradur√≠a']
            for keyword in authority_keywords:
                if keyword in content.lower():
                    metadata['authority'] = keyword
        
        return metadata
    
    def extract_from_visual_elements(self, docling_json, file_info):
        """Extraer metadata desde elementos visuales (sellos, logos)"""
        metadata = {}
        
        # Analizar im√°genes con OCR
        for picture in docling_json.get('pictures', []):
            if picture.get('confidence', 0) > 0.6:
                ocr_text = picture.get('ocr_text', '')
                
                # Buscar sellos institucionales
                institutional_keywords = [
                    'tribunal superior', 'juzgado', 'fiscal√≠a',
                    'procuradur√≠a', 'consejo superior'
                ]
                
                for keyword in institutional_keywords:
                    if keyword in ocr_text.lower():
                        metadata['authority'] = keyword
                        break
        
        return metadata
    
    def extract_from_context_patterns(self, docling_json, file_info):
        """Extraer metadata usando patrones contextuales"""
        metadata = {}
        
        # Analizar todos los textos disponibles
        all_texts = []
        for text in docling_json.get('texts', []):
            all_texts.append(text.get('content', ''))
        
        combined_text = ' '.join(all_texts)
        
        # Patrones de contexto para inferir tipo de documento
        context_patterns = {
            'judicial': ['sentencia', 'fallo', 'juzgado', 'tribunal'],
            'coactivo': ['coactivo', 'embargo', 'secuestro'],
            'administrativo': ['resoluci√≥n', 'acto administrativo', 'oficio']
        }
        
        for doc_type, patterns in context_patterns.items():
            if any(pattern in combined_text.lower() for pattern in patterns):
                metadata['document_type'] = doc_type
                break
        
        return metadata
    
    def validate_metadata(self, metadata):
        """Validar que la metadata extra√≠da sea razonable"""
        # Al menos debe tener un tipo de documento o expediente
        return (metadata.get('document_type') != 'unknown' or 
                metadata.get('expedient_number') is not None)
```

#### **B. Sistema de Confianza y Calidad**

```python
class MetadataConfidenceScorer:
    def calculate_metadata_confidence(self, metadata, extraction_method):
        """Calcular nivel de confianza de la metadata extra√≠da"""
        confidence = 0.0
        
        # Peso por m√©todo de extracci√≥n
        method_weights = {
            'ocr': 1.0,
            'extract_from_filename': 0.8,
            'extract_from_filepath': 0.7,
            'extract_from_document_structure': 0.9,
            'extract_from_visual_elements': 0.6,
            'extract_from_context_patterns': 0.5
        }
        
        base_confidence = method_weights.get(extraction_method, 0.5)
        
        # Ajustar por calidad de datos extra√≠dos
        quality_factors = {
            'has_expedient': 0.3,
            'has_date': 0.2,
            'has_authority': 0.2,
            'has_document_type': 0.2,
            'has_legal_references': 0.1
        }
        
        for factor, weight in quality_factors.items():
            if self.has_quality_factor(metadata, factor):
                confidence += weight
        
        return min(confidence * base_confidence, 1.0)
    
    def has_quality_factor(self, metadata, factor):
        """Verificar si la metadata tiene un factor de calidad espec√≠fico"""
        factor_checks = {
            'has_expedient': lambda m: m.get('expedient_number') is not None,
            'has_date': lambda m: m.get('date') is not None,
            'has_authority': lambda m: m.get('authority') is not None,
            'has_document_type': lambda m: m.get('document_type') != 'unknown',
            'has_legal_references': lambda m: len(m.get('legal_references', [])) > 0
        }
        
        return factor_checks.get(factor, lambda m: False)(metadata)
```

#### **C. Metadata Enriquecida con Informaci√≥n Estructural**

```python
def create_enhanced_legal_metadata(docling_json, file_info, ocr_metadata):
    """Crear metadata enriquecida combinando m√∫ltiples fuentes"""
    
    enhanced_metadata = {
        # Metadata b√°sica
        "document_type": ocr_metadata.get('document_type', 'unknown'),
        "expedient_number": ocr_metadata.get('expedient_number'),
        "jurisdiction": "colombia",
        "date": ocr_metadata.get('date'),
        "authority": ocr_metadata.get('authority'),
        "legal_references": ocr_metadata.get('legal_references', []),
        "confidence_score": ocr_metadata.get('confidence_score', 0.0),
        "extraction_method": ocr_metadata.get('extraction_method', 'unknown'),
        
        # Metadata estructural
        "structural_info": {
            "total_pages": len(set(text.get('page_no', 0) for text in docling_json.get('texts', [])),
            "total_tables": len(docling_json.get('tables', [])),
            "total_images": len(docling_json.get('pictures', [])),
            "total_groups": len(docling_json.get('groups', [])),
            "ocr_quality": calculate_overall_ocr_quality(docling_json)
        },
        
        # Metadata de archivo
        "file_info": {
            "filename": file_info.get('filename'),
            "filepath": file_info.get('filepath'),
            "file_size": file_info.get('file_size'),
            "creation_date": file_info.get('creation_date')
        },
        
        # Metadata de procesamiento
        "processing_info": {
            "processing_date": datetime.now().isoformat(),
            "processor_version": "1.0.0",
            "fallback_used": ocr_metadata.get('extraction_method') != 'ocr'
        }
    }
    
    return enhanced_metadata

def calculate_overall_ocr_quality(docling_json):
    """Calcular calidad general del OCR del documento"""
    texts = docling_json.get('texts', [])
    if not texts:
        return 0.0
    
    total_confidence = sum(text.get('confidence', 0) for text in texts)
    return total_confidence / len(texts)
```

### Estrategia de Fallback Completa

```python
class RobustLegalMetadataExtractor:
    def __init__(self):
        self.extractors = [
            OCRMetadataExtractor(),
            FilenameMetadataExtractor(),
            FilepathMetadataExtractor(),
            StructureMetadataExtractor(),
            VisualMetadataExtractor(),
            ContextMetadataExtractor()
        ]
    
    def extract_with_fallbacks(self, docling_json, file_info):
        """Extraer metadata con m√∫ltiples estrategias de fallback"""
        
        results = []
        
        # Intentar cada extractor
        for extractor in self.extractors:
            try:
                metadata = extractor.extract(docling_json, file_info)
                confidence = self.calculate_confidence(metadata, extractor.name)
                metadata['confidence'] = confidence
                results.append(metadata)
            except Exception as e:
                logger.warning(f"Extractor {extractor.name} failed: {e}")
        
        # Seleccionar el mejor resultado
        if results:
            best_result = max(results, key=lambda x: x['confidence'])
            return self.merge_metadata(results, best_result)
        
        # Metadata por defecto si todo falla
        return self.create_default_metadata(file_info)
    
    def merge_metadata(self, results, best_result):
        """Combinar metadata de m√∫ltiples extractores"""
        merged = best_result.copy()
        
        # Complementar con informaci√≥n de otros extractores
        for result in results:
            if result != best_result:
                for key, value in result.items():
                    if key not in merged or merged[key] is None:
                        merged[key] = value
        
        return merged
```

## üóÑÔ∏è Arquitectura de Base de Datos Vectorial

### Estructura del Documento Vectorial

```python
vector_document = {
    # Contenido principal
    "content": "texto del chunk...",
    "content_vector": [0.1, 0.2, 0.3, ...],
    
    # Metadata jur√≠dica robusta con fallbacks
    "legal_metadata": {
        # Metadata b√°sica (con fallbacks)
        "document_type": "oficio_juridico",
        "expedient_number": "IQ051008152850",
        "jurisdiction": "colombia",
        "date": "2024-01-15",
        "authority": "tribunal_superior",
        "legal_references": ["art√≠culo 123", "ley 1234"],
        "confidence_score": 0.95,
        "extraction_method": "ocr|filename|filepath|structure|visual|context",
        
        # Metadata estructural del documento
        "structural_info": {
            "total_pages": 5,
            "total_tables": 2,
            "total_images": 3,
            "total_groups": 1,
            "ocr_quality": 0.85
        },
        
        # Metadata de archivo
        "file_info": {
            "filename": "Bog_IQ051008152850.pdf",
            "filepath": "docs/0811202/Judicial/",
            "file_size": 2048576,
            "creation_date": "2024-01-15T10:30:00Z"
        },
        
        # Metadata de procesamiento
        "processing_info": {
            "processing_date": "2024-01-15T15:45:00Z",
            "processor_version": "1.0.0",
            "fallback_used": True,
            "fallback_methods": ["filename", "filepath"]
        }
    },
    
    # Informaci√≥n estructural
    "structural_metadata": {
        "chunk_type": "text|table|header|image",
        "page_number": 1,
        "bbox": {"l": 100, "t": 200, "r": 300, "b": 250},
        "context_hierarchy": ["t√≠tulo", "secci√≥n", "art√≠culo"],
        "parent_chunk_id": "chunk_123"
    },
    
    # Informaci√≥n de b√∫squeda
    "search_metadata": {
        "keywords": ["expediente", "radicaci√≥n", "fecha"],
        "semantic_tags": ["procedimiento", "administrativo"],
        "cross_references": ["chunk_456", "chunk_789"]
    }
}
```

### Estrategias de Indexaci√≥n

#### **A. √çndices M√∫ltiples**

```python
# 1. √çndice sem√°ntico principal
semantic_index = create_vector_index(
    vectors=content_vectors,
    similarity_metric='cosine'
)

# 2. √çndice de metadata
metadata_index = create_vector_index(
    vectors=metadata_vectors,
    similarity_metric='cosine'
)

# 3. √çndice h√≠brido
hybrid_index = create_hybrid_index(
    vector_queries=content_vectors,
    keyword_queries=legal_keywords,
    weight_vector=0.7,
    weight_keyword=0.3
)
```

#### **B. Particionamiento por Tipo**

```python
# Separar chunks por tipo para b√∫squedas especializadas
indexes = {
    'text_chunks': create_index(text_chunks),
    'table_chunks': create_index(table_chunks),
    'header_chunks': create_index(header_chunks),
    'image_chunks': create_index(image_chunks)
}
```

## üîÑ Estrategias de Vectorizaci√≥n

### Vectorizaci√≥n M√∫ltiple

```python
def create_legal_vectors(chunk):
    vectors = {}
    
    # 1. Vector del contenido principal
    vectors['content_vector'] = embed_text(chunk.content)
    
    # 2. Vector de metadata jur√≠dica
    legal_text = f"{chunk.metadata['document_type']} {chunk.metadata['jurisdiction']} {chunk.metadata['expedient_number']}"
    vectors['metadata_vector'] = embed_text(legal_text)
    
    # 3. Vector de contexto estructural
    context_text = " ".join(chunk.context_hierarchy)
    vectors['context_vector'] = embed_text(context_text)
    
    # 4. Vector combinado (para b√∫squeda h√≠brida)
    combined_text = f"{chunk.content} {legal_text} {context_text}"
    vectors['combined_vector'] = embed_text(combined_text)
    
    return vectors
```

### Modelos de Embedding Especializados

```python
# Para documentos jur√≠dicos, usar modelos especializados
legal_embedding_models = {
    'content': 'sentence-transformers/all-MiniLM-L6-v2',
    'legal': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
    'spanish_legal': 'dccuchile/bert-base-spanish-wwm-cased'
}
```

## üîç Estrategias de Retrieval

### B√∫squeda H√≠brida

```python
def legal_document_search(query, filters=None):
    results = []
    
    # 1. B√∫squeda sem√°ntica
    semantic_results = semantic_index.search(
        query_vector=embed_query(query),
        top_k=10
    )
    
    # 2. B√∫squeda por metadata
    metadata_results = metadata_index.search(
        query_vector=embed_query(query),
        filters=filters,  # Expediente, fecha, jurisdicci√≥n
        top_k=5
    )
    
    # 3. B√∫squeda por keywords
    keyword_results = keyword_index.search(
        query=extract_legal_keywords(query),
        top_k=5
    )
    
    # 4. Combinar y re-rank
    combined_results = combine_and_rerank(
        semantic_results, metadata_results, keyword_results
    )
    
    return combined_results
```

### B√∫squeda Contextual

```python
def contextual_legal_search(query, context_chunk_id=None):
    # Si tenemos contexto previo, buscar chunks relacionados
    if context_chunk_id:
        related_chunks = find_related_chunks(context_chunk_id)
        context_query = f"{query} {related_chunks}"
    else:
        context_query = query
    
    return semantic_index.search(context_query)
```

## üõ†Ô∏è Implementaci√≥n Pr√°ctica

### Con Pinecone

```python
import pinecone

# Configurar Pinecone
pinecone.init(api_key="your_key", environment="your_env")
index_name = "legal-documents"

# Crear √≠ndice
pinecone.create_index(
    name=index_name,
    dimension=384,  # Dimensi√≥n del embedding
    metric="cosine"
)

# Insertar chunks
index = pinecone.Index(index_name)
index.upsert(vectors=legal_chunks_with_vectors)
```

### Con ChromaDB

```python
import chromadb

# Crear cliente
client = chromadb.Client()

# Crear colecci√≥n
collection = client.create_collection(
    name="legal_documents",
    metadata={"hnsw:space": "cosine"}
)

# Insertar documentos
collection.add(
    documents=[chunk.content for chunk in chunks],
    metadatas=[chunk.metadata for chunk in chunks],
    embeddings=[chunk.vector for chunk in chunks],
    ids=[chunk.id for chunk in chunks]
)
```

## üìä Casos de Uso Espec√≠ficos

### B√∫squeda por Expediente

```python
# Buscar todos los chunks de un expediente espec√≠fico
results = vector_db.search(
    query="expediente IQ051008152850",
    filter={"expedient_number": "IQ051008152850"}
)
```

### B√∫squeda por Referencia Legal

```python
# Buscar chunks que mencionen una ley espec√≠fica
results = vector_db.search(
    query="art√≠culo 123 c√≥digo civil",
    filter={"legal_references": {"$contains": "art√≠culo 123"}}
)
```

### B√∫squeda por Fecha

```python
# Buscar documentos de un per√≠odo espec√≠fico
results = vector_db.search(
    query="procedimiento administrativo",
    filter={"date": {"$gte": "2024-01-01", "$lte": "2024-12-31"}}
)
```

### B√∫squeda por Tipo de Documento

```python
# Buscar solo tablas o headers
results = vector_db.search(
    query="informaci√≥n de radicaci√≥n",
    filter={"chunk_type": "table"}
)
```

### B√∫squeda por M√©todo de Extracci√≥n

```python
# Buscar documentos donde se us√≥ fallback
results = vector_db.search(
    query="expediente judicial",
    filter={"legal_metadata.extraction_method": {"$in": ["filename", "filepath"]}}
)

# Buscar documentos con alta confianza de OCR
results = vector_db.search(
    query="sentencia tribunal",
    filter={"legal_metadata.confidence_score": {"$gte": 0.8}}
)
```

### B√∫squeda por Calidad de OCR

```python
# Buscar documentos con buena calidad de OCR
results = vector_db.search(
    query="procedimiento administrativo",
    filter={"legal_metadata.structural_info.ocr_quality": {"$gte": 0.7}}
)
```

## ‚ö° Consideraciones de Rendimiento

### Optimizaci√≥n de Chunks

#### **A. Tama√±o √ìptimo de Chunks:**
- **Textos**: 500-1000 tokens
- **Tablas**: Chunk √∫nico por tabla
- **Headers**: Chunks separados
- **Im√°genes**: Chunk √∫nico con OCR

#### **B. Estrategias de Caching:**
```python
# Cache de embeddings
embedding_cache = {}

def get_cached_embedding(text, model_name):
    cache_key = f"{hash(text)}_{model_name}"
    if cache_key not in embedding_cache:
        embedding_cache[cache_key] = embed_text(text, model_name)
    return embedding_cache[cache_key]
```

#### **C. Procesamiento por Lotes:**
```python
def batch_process_chunks(chunks, batch_size=100):
    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i + batch_size]
        vectors = embed_batch(batch)
        insert_batch_to_vector_db(batch, vectors)
```

### Monitoreo y M√©tricas

#### **A. M√©tricas de Calidad:**
- **Precisi√≥n de Retrieval**: % de chunks relevantes recuperados
- **Cobertura**: % de informaci√≥n jur√≠dica capturada
- **Latencia**: Tiempo de respuesta de b√∫squeda

#### **B. M√©tricas de Rendimiento:**
- **Throughput**: Chunks procesados por segundo
- **Uso de Memoria**: Consumo de recursos
- **Tiempo de Indexaci√≥n**: Velocidad de inserci√≥n

## üéØ Ventajas de esta Estrategia

### ‚úÖ Preservaci√≥n de Estructura Jur√≠dica
- Encabezados como chunks separados
- Tablas con estructura preservada
- Jerarqu√≠a de contexto mantenida

### ‚úÖ Metadata Enriquecida con Fallbacks
- Informaci√≥n jur√≠dica espec√≠fica
- Referencias cruzadas
- Confianza del OCR
- **M√∫ltiples fuentes de extracci√≥n**
- **Sistema de confianza robusto**
- **Metadata estructural completa**

### ‚úÖ Optimizaci√≥n para B√∫squeda
- Chunks sem√°nticamente coherentes
- Contexto preservado
- Relaciones entre elementos
- **Filtros por calidad de extracci√≥n**
- **B√∫squedas por m√©todo de procesamiento**

### ‚úÖ Escalabilidad
- Procesamiento por lotes
- Metadata consistente
- F√°cil integraci√≥n con sistemas RAG
- **Sistema de fallbacks autom√°tico**
- **Monitoreo de calidad de extracci√≥n**

### ‚úÖ Robustez ante OCR Deficiente
- **Extracci√≥n desde nombres de archivo**
- **An√°lisis de estructura de carpetas**
- **Patrones contextuales**
- **Elementos visuales (sellos, logos)**
- **Combinaci√≥n inteligente de fuentes**

## üìà Implementaci√≥n en Fases

### Fase 1: Procesamiento B√°sico
- [ ] Implementar procesador de JSON DoclingDocument
- [ ] Crear chunking b√°sico por tipo de elemento
- [ ] Extraer metadata jur√≠dica b√°sica

### Fase 2: Enriquecimiento Avanzado
- [ ] Implementar extracci√≥n de referencias legales
- [ ] Crear sistema de contexto jer√°rquico
- [ ] Desarrollar vectorizaci√≥n m√∫ltiple

### Fase 3: Base de Datos Vectorial
- [ ] Configurar √≠ndices m√∫ltiples
- [ ] Implementar b√∫squeda h√≠brida
- [ ] Optimizar rendimiento

### Fase 4: Integraci√≥n RAG
- [ ] Conectar con sistema de generaci√≥n
- [ ] Implementar re-ranking
- [ ] Monitoreo y m√©tricas

---

**Nota**: Esta estrategia est√° dise√±ada espec√≠ficamente para documentos jur√≠dicos colombianos procesados con DoclingDocument JSON, optimizando tanto la precisi√≥n como el rendimiento para casos de uso legales espec√≠ficos.
